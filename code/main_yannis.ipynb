{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# -*- author : Vincent Roduit - Yannis Laaroussi - Fabio Palmisano - Vincent Roh - Alexi Semiz -*-\n",
    "# -*- date : 2023-11-15 -*-\n",
    "# -*- Last revision: 2023-11-15 -*-\n",
    "# -*- python version : 3.9.13 -*-\n",
    "# -*- Description: Main Containing all the meaningfull results -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import nltk\n",
    "from nltk import bigrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from statsmodels.stats import diagnostic\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind, ttest_rel\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import functions\n",
    "from read.read_functions import read_txt\n",
    "from read.pickle_functions import *\n",
    "from create_all_users import create_all_users\n",
    "from create_rating_statistic import create_ratings_stat\n",
    "from create_all_beers import *\n",
    "\n",
    "#import cleaning functions\n",
    "from cleaning_functions.matched_beer import *\n",
    "from cleaning_functions.rate_beer import *\n",
    "from cleaning_functions.advocate import *\n",
    "\n",
    "#import functions for the analysis\n",
    "from compute_experts import *\n",
    "\n",
    "#import functions for text analysis\n",
    "from textual_analysis import detect_language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Download and save datas\n",
    "### Data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data paths for raw files\n",
    "beer_advocate_path = '../datas/BeerAdvocate/'\n",
    "matched_beer_data_path = '../datas/matched_beer_data/'\n",
    "rate_beer_path = '../datas/RateBeer/'\n",
    "\n",
    "advocate_beers_path = beer_advocate_path + 'beers.csv'\n",
    "advovate_breweries_path = beer_advocate_path + 'breweries.csv'\n",
    "advocate_ratings_path = beer_advocate_path + 'ratings.txt'\n",
    "advocate_reviews_path = beer_advocate_path + 'reviews.txt'\n",
    "advocate_users_path = beer_advocate_path + 'users.csv'\n",
    "\n",
    "matched_beer_beers = matched_beer_data_path + 'beers.csv'\n",
    "matched_beer_breweries = matched_beer_data_path + 'breweries.csv'\n",
    "matched_beer_ratings_ba = matched_beer_data_path + 'ratings_ba.txt'\n",
    "matched_beer_ratings_rb = matched_beer_data_path + 'ratings_rb.txt'\n",
    "matched_beer_ratings = matched_beer_data_path + 'ratings.csv'\n",
    "matched_beer_users_approx = matched_beer_data_path + 'users_approx.csv'\n",
    "matched_beer_users = matched_beer_data_path + 'users.csv'\n",
    "\n",
    "rate_beer_beers = rate_beer_path + 'beers.csv'\n",
    "rate_beer_breweries = rate_beer_path + 'breweries.csv'\n",
    "rate_beer_users = rate_beer_path + 'users.csv'\n",
    "rate_beer_ratings = rate_beer_path + 'ratings.txt'\n",
    "rate_beer_reviews = rate_beer_path + 'reviews.txt'\n",
    "\n",
    "contries_path = '../datas/countries/countries.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data paths for pickle files\n",
    "beer_advocate_path_pickle = '../datas/BeerAdvocate/pickles/df_advocate_'\n",
    "matched_beer_data_path_pickle = '../datas/matched_beer_data/pickles/df_matched_beer_'\n",
    "rate_beer_path_pickle = '../datas/RateBeer/pickles/df_rate_beer_'\n",
    "\n",
    "advocate_beers_path_pickle = beer_advocate_path_pickle + 'beers.pkl'\n",
    "advovate_breweries_path_pickle = beer_advocate_path_pickle + 'breweries.pkl'\n",
    "advocate_ratings_path_pickle = beer_advocate_path_pickle + 'ratings.pkl'\n",
    "advocate_reviews_path_pickle = beer_advocate_path_pickle + 'reviews.pkl'\n",
    "advocate_users_path_pickle = beer_advocate_path_pickle + 'users.pkl'\n",
    "\n",
    "matched_beer_beers_pickle = matched_beer_data_path_pickle + 'beers.pkl'\n",
    "matched_beer_breweries_pickle = matched_beer_data_path_pickle + 'breweries.pkl'\n",
    "matched_beer_ratings_ba_pickle = matched_beer_data_path_pickle + 'ratings_ba.pkl'\n",
    "matched_beer_ratings_rb_pickle = matched_beer_data_path_pickle + 'ratings_rb.pkl'\n",
    "matched_beer_ratings_pickle = matched_beer_data_path_pickle + 'ratings.pkl'\n",
    "matched_beer_users_approx_pickle = matched_beer_data_path_pickle + 'users_approx.pkl'\n",
    "matched_beer_users_pickle = matched_beer_data_path_pickle + 'users.csv'\n",
    "\n",
    "rate_beer_beers_pickle = rate_beer_path_pickle + 'beers.pkl'\n",
    "rate_beer_breweries_pickle = rate_beer_path_pickle + 'breweries.pkl'\n",
    "rate_beer_users_pickle = rate_beer_path_pickle + 'users.pkl'\n",
    "rate_beer_ratings_pickle = rate_beer_path_pickle + 'ratings.pkl'\n",
    "rate_beer_reviews_pickle = rate_beer_path_pickle + 'reviews.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define list of datas for each website\n",
    "datas_matched_beer_names = [\n",
    "    'df_matched_beer_beers',\n",
    "    'df_matched_beer_breweries',\n",
    "    'df_matched_beer_ratings_ba',\n",
    "    'df_matched_beer_ratings_rb',\n",
    "    'df_matched_beer_ratings',\n",
    "    'df_matched_beer_users_approx',\n",
    "    'df_matched_beer_users'\n",
    "    ]\n",
    "datas_advocate_names = [\n",
    "    'df_advocate_beers',\n",
    "    'df_advocate_breweries',\n",
    "    'df_advocate_ratings',\n",
    "    'df_advocate_reviews',\n",
    "    'df_advocate_users'\n",
    "    ]\n",
    "datas_rate_beer_names = [\n",
    "    'df_rate_beer_beers',\n",
    "    'df_rate_beer_breweries',\n",
    "    'df_rate_beer_users',\n",
    "    'df_rate_beer_ratings',\n",
    "    'df_rate_beer_reviews'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Format\n",
    "$\\color{Red}{\\text{Attention}}$ : Run the celluls in this section only if the datasets stored as pickle are not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datas from Advovate Beer\n",
    "df_advocate_beers = pd.read_csv(advocate_beers_path, sep=',')\n",
    "df_advocate_breweries = pd.read_csv(advovate_breweries_path, sep=',')\n",
    "df_advocate_ratings = read_txt(advocate_ratings_path)\n",
    "df_advocate_reviews = read_txt(advocate_reviews_path)\n",
    "df_advocate_users = pd.read_csv(advocate_users_path, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datas from Matched Beer\n",
    "df_matched_beer_beers = pd.read_csv(matched_beer_beers, sep=',')\n",
    "df_matched_beer_breweries = pd.read_csv(matched_beer_breweries, sep=',')\n",
    "df_matched_beer_ratings_ba = read_txt(matched_beer_ratings_ba)\n",
    "df_matched_beer_ratings_rb = read_txt(matched_beer_ratings_rb)\n",
    "df_matched_beer_ratings = pd.read_csv(matched_beer_ratings, sep=',')\n",
    "df_matched_beer_users_approx = pd.read_csv(matched_beer_users_approx)\n",
    "df_matched_beer_users = pd.read_csv(matched_beer_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datas from Rate Beer\n",
    "df_rate_beer_beers = pd.read_csv(rate_beer_beers, sep=',')\n",
    "df_rate_beer_breweries = pd.read_csv(rate_beer_breweries, sep=',')\n",
    "df_rate_beer_users = pd.read_csv(rate_beer_users, sep=',')\n",
    "df_rate_beer_ratings = read_txt(rate_beer_ratings)\n",
    "df_rate_beer_reviews = read_txt(rate_beer_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import raw data sets\n",
    "df_matched_beer_beers, df_matched_beer_breweries, df_matched_beer_ratings_ba, df_matched_beer_ratings_rb, df_matched_beer_ratings, df_matched_beer_users_approx, df_matched_beer_users = load_datas('matched_beer_data', datas_matched_beer_names)\n",
    "df_advocate_beers, df_advocate_breweries, df_advocate_ratings, df_advocate_reviews, df_advocate_users = load_datas('BeerAdvocate', datas_advocate_names)\n",
    "df_rate_beer_beers,df_rate_beer_breweries,df_rate_beer_users,df_rate_beer_ratings,df_rate_beer_reviews = load_datas('RateBeer', datas_rate_beer_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store dataFrame (Pickle format)\n",
    "Use this section to store the datasets in pickle (normally done once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define list of datas for each website\n",
    "datas_rate_beer = [df_rate_beer_beers,df_rate_beer_breweries,df_rate_beer_users,df_rate_beer_ratings,df_rate_beer_reviews]\n",
    "datas_matched_beer = [df_matched_beer_beers,df_matched_beer_breweries,df_matched_beer_ratings_ba,df_matched_beer_ratings_rb,df_matched_beer_ratings,df_matched_beer_users_approx,df_matched_beer_users]\n",
    "datas_advocate_beer = [df_advocate_beers,df_advocate_breweries,df_advocate_ratings,df_advocate_reviews,df_advocate_users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving datas\n",
    "save_datas('RateBeer', datas_rate_beer,datas_rate_beer_names)\n",
    "save_datas('matched_beer_data', datas_matched_beer,datas_matched_beer_names)\n",
    "save_datas('BeerAdvocate', datas_advocate_beer,datas_advocate_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Initial data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preprocessing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  A first merge is performed on user's datasets in order to have a single dataFrame. \n",
    "* Another merge is done on beer DataFrame to provide a single dataFrame containing all beers\n",
    "* A last merge is performed on ratings (for both Advocate and Rate Beer) to obtain a single dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_users = df_matched_beer_users\n",
    "users, mb_users_index = clean_mb_users(mb_users)\n",
    "advocate_users = deepcopy(df_advocate_users)\n",
    "advocate_users = clean_advocate_users(advocate_users)\n",
    "rb_users = df_rate_beer_users\n",
    "rb_users = clean_rb_users(rb_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_users = create_all_users(advocate_users,mb_users,rb_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_beers = df_advocate_beers\n",
    "rb_beers = df_rate_beer_beers\n",
    "mb_beers = df_matched_beer_beers\n",
    "adv_beers = clean_advocate_beers(adv_beers)\n",
    "rb_beers = clean_rb_beers(rb_beers)\n",
    "mb_beers = clean_mb_beers(mb_beers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_beers = create_all_beers(adv_beers,rb_beers,mb_beers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_ratings = df_advocate_ratings\n",
    "rb_ratings = df_rate_beer_ratings\n",
    "ba_ratings = clean_advocate_ratings(ba_ratings,df_all_beers)\n",
    "rb_ratings = clean_rb_ratings(rb_ratings,df_all_beers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_stats = create_ratings_stat(ba_ratings,rb_ratings,df_all_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv_reviews = clean_advocate_reviews(df_advocate_reviews)\n",
    "df_rb_reviews = clean_rb_reviews(df_rate_beer_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Diving in the datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Distribution of the number of ratings per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_per_user = pd.DataFrame({'nbr_ratings':df_ratings_stats.groupby('user_id')['user_id'].count()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_per_user.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.ecdfplot(ratings_per_user, label=\"nbr_ratings\", complementary=True)\n",
    "plt.title('Cumulative histogram of the number of ratings per user (all websites)')\n",
    "plt.xlabel('Number of ratings')\n",
    "plt.ylabel('Proportion')\n",
    "plt.semilogx()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution has a heavy tail, indicating that there are numerous users who have posted only a few ratings, and conversely, a small number of users who are prolific raters. This observation motivates us to delve deeper into understanding the distinctions between these prolific raters and the rest of the user population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.a) Define who is a massive rater \n",
    "In order to separate people in two group, a definition of a massive rater, called from now an \"expert\" has to be found. The choice was made here to consider the number of ratings per year and aggregate scores from the past 3 years with the formula:\n",
    "$$\n",
    "S_{Y_j} = 2 * R_{Y_{j}} + 0.5 * R_{Y_{j-1}} + 0.25 * R_{Y_{j-2}} + 0.1 * R_{Y_{j-3}}\n",
    "$$\n",
    ", where $R_{Y_j}$ denotes the number of ratings for the year j and $S_{Y_j}$ is the score of the user for the year j.\n",
    "The experts are then people from the 0.995 quantile of the score calculate previously (among those who have a non-zero score i.e active users)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the expert users\n",
    "df_ratings_stat_expert, df_ratings_stat_pivot = compute_experts_table(df_ratings_stats)\n",
    "df_ratings_stat_expert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a dictionary of experts per year\n",
    "experts_dict = {}\n",
    "for year in range(1996, 2018):\n",
    "    experts_dict[year] = df_ratings_stat_expert.loc[(df_ratings_stat_expert[\"year\"] == year) & (df_ratings_stat_expert[\"is_expert\"] == 1)].user_id.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_stats[\"is_expert\"]=df_ratings_stats[[\"user_id\",\"year\"]].apply(lambda x: 1 if x[\"user_id\"] in experts_dict[x[\"year\"]] else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expert_per_year = df_ratings_stat_expert.groupby('year').apply(lambda x: sum(x['is_expert']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expert_per_year.plot(kind='bar', figsize=(15,5))\n",
    "plt.ylabel('Number of experts')\n",
    "plt.xlabel('Year')\n",
    "plt.title('Number of experts per year')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Analysis of the behavior of the two categories\n",
    "#### 1.2.a) Mean of the ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this section is to analyze if the experts are more severe than the rest of the population on the global rating (column 'rating' in the DataFrame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ratings_expert = []\n",
    "avg_ratings_normal = []\n",
    "ttest_expert_normal = []\n",
    "\n",
    "interest_years = sorted([year for year in df_ratings_stats.year.unique() if year > 2002])\n",
    "\n",
    "for year in interest_years:\n",
    "    df_expert_year = df_ratings_stat_expert.query('year == @year')\n",
    "    df_ratings_stat_year = df_ratings_stats.query('year == @year')\n",
    "    expert_of_the_year = df_expert_year[df_expert_year.is_expert].user_id\n",
    "    avg_expert = df_ratings_stat_year[df_ratings_stat_year['user_id'].isin(expert_of_the_year)]['rating'].mean()\n",
    "    avg_normal = df_ratings_stat_year[~df_ratings_stat_year['user_id'].isin(expert_of_the_year)]['rating'].mean()\n",
    "    ttest = stats.ttest_ind(df_ratings_stat_year[df_ratings_stat_year['user_id'].isin(expert_of_the_year)]['rating'], df_ratings_stat_year[~df_ratings_stat_year['user_id'].isin(expert_of_the_year)]['rating'])\n",
    "    ttest_expert_normal.append(ttest)\n",
    "    avg_ratings_expert.append(avg_expert)\n",
    "    avg_ratings_normal.append(avg_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_width = 0.35\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "bar_positions1 = np.arange(len(avg_ratings_expert))\n",
    "bar_positions2 = bar_positions1 + bar_width\n",
    "\n",
    "ax.bar(bar_positions1, avg_ratings_normal, width=bar_width, label='Casuals', color='blue', alpha=0.7)\n",
    "ax.bar(bar_positions2, avg_ratings_expert, width=bar_width, label='Experts', color='red', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Years')\n",
    "ax.set_ylabel('Average ratings')\n",
    "ax.set_title('Average of ratings between experts and casuals per year ')\n",
    "ax.set_xticks(bar_positions1 + bar_width / 2)\n",
    "ax.set_xticklabels(interest_years, rotation=45, ha='right')\n",
    "\n",
    "y_min = min(min(avg_ratings_normal), min(avg_ratings_expert)) - 1 \n",
    "y_max = max(max(avg_ratings_normal), max(avg_ratings_expert)) + 1 \n",
    "ax.set_ylim(y_min, y_max)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this graph it is clear that the expert are more severe, but let's verify with the mean of a T-Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(len(ttest_expert_normal)):\n",
    "    if ttest_expert_normal[year][1] < 0.05:\n",
    "        print(f'The p-value for the year {interest_years[year]} is {ttest_expert_normal[year][1]:.2e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t-test tells that the hypothesis H0, under which the mean for the two groups are equals, can be rejected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.b) Top 10 rated beers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the assessment focuses on whether experts and the general population share similar preferences when it comes to rating beers. For this investigation, the beers are sorted based on the number of times they were rated. A comparison is then made between the top 10 beers for the two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_10_experts = pd.DataFrame()\n",
    "df_top_10_rest = pd.DataFrame()\n",
    "\n",
    "interest_years = sorted([year for year in df_ratings_stats.year.unique() if year > 2002])\n",
    "\n",
    "for year in interest_years:\n",
    "    top_10_rest = []\n",
    "    df_expert_year = df_ratings_stat_expert.query('year == @year')\n",
    "    df_ratings_stat_year = df_ratings_stats.query('year == @year')\n",
    "    expert_of_the_year = df_expert_year[df_expert_year.is_expert].user_id\n",
    "    top_10_rest = df_ratings_stat_year[~df_ratings_stat_year['user_id'].isin(expert_of_the_year)].copy()\n",
    "    top_10_rest = top_10_rest.groupby('beer_id').agg({'rating': 'count', 'beer_name': 'first'})\n",
    "    top_10_rest = top_10_rest.sort_values(by='rating', ascending=False).head(10)\n",
    "\n",
    "    df_top_10_rest[f'{year}'] = top_10_rest['beer_name'].values\n",
    "    top_10_experts = df_ratings_stat_year[df_ratings_stat_year['user_id'].isin(expert_of_the_year)].copy()\n",
    "    top_10_experts = top_10_experts.groupby('beer_id').agg({'rating': 'count', 'beer_name': 'first'})\n",
    "    top_10_experts = top_10_experts.sort_values(by='rating', ascending=False).head(10)\n",
    "    df_top_10_experts[f'{year}'] = top_10_experts['beer_name'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = {}\n",
    "for col in df_top_10_experts.columns:\n",
    "    value = df_top_10_experts[col].isin(df_top_10_rest[col]).sum()\n",
    "    similarity[col] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in similarity:\n",
    "    if similarity[key] > 0:\n",
    "        print(f'Year {key} has {similarity[key]} beer(s) in common')\n",
    "        common_beers = df_top_10_experts[df_top_10_experts[key].isin(df_top_10_rest[key])][key].values\n",
    "        print(common_beers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.c) We are going to see what kind (in terms of popularity) of beer casuals and expert rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each rating, we compute the number of ratings done the previous year on the rated beers. It gives an idea of the popularity of the rated beer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_beer_year=df_ratings_stats.groupby([\"beer_id\",\"year\"]).agg(\"size\").reset_index(name=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_beer_year_shifted = df_grouped_beer_year.copy()\n",
    "df_grouped_beer_year_shifted['year'] += 1\n",
    "df_grouped_beer_year_shifted.rename(columns={\"count\": \"count_last_year\"}, inplace=True)\n",
    "df_ratings_stats = df_ratings_stats.merge(df_grouped_beer_year_shifted, how='left', on=['beer_id', 'year'])\n",
    "df_ratings_stats.fillna({\"count_last_year\":0}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyse ratings of year 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_this_year,experts_this_year=filter_year_and_add_is_expert(df_ratings_stats,2016,df_ratings_stat_expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_ratings_year_minus1_experts=df_ratings_this_year.loc[df_ratings_this_year[\"is_expert\"]==1][\"count_last_year\"]\n",
    "nbr_ratings_year_minus1_non_experts=df_ratings_this_year.loc[df_ratings_this_year[\"is_expert\"]==0][\"count_last_year\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "\n",
    "color = 'tab:orange'\n",
    "ax1.set_xlabel('Number of ratings per beer in 2015')\n",
    "ax1.set_ylabel('Ratings counts in 2016', color=color)\n",
    "ax1.hist(nbr_ratings_year_minus1_non_experts, bins=100, log=True, alpha=0.5, color=\"orange\", label=\"Non experts\",zorder=2)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid(False)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Ratings count in 2016', color=color)\n",
    "ax2.hist(nbr_ratings_year_minus1_experts, bins=100, log=True, alpha=0.5, color=\"blue\", label=\"Experts\",zorder=1)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.grid(False)\n",
    "red_patch = mpatches.Patch(color='orange', label='non experts')\n",
    "blue_patch = mpatches.Patch(color='blue', label='experts')\n",
    "ax1.legend(handles=[red_patch, blue_patch])\n",
    "plt.title(\"Distribution of number of ratings per beer in 2015 of ratings in 2016\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see that experts rate less popular beers, let's perform a ttest to check this assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(nbr_ratings_year_minus1_experts,nbr_ratings_year_minus1_non_experts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  ttest confirms the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we group the reults by user and use the mean this time :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_nbr_ratings_years_minus_one_per_user=df_ratings_this_year.groupby([\"user_id\",\"is_expert\"])[\"count_last_year\"].agg(\"mean\").reset_index().set_index(\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_nbr_ratings_years_minus_one_per_user_experts=mean_nbr_ratings_years_minus_one_per_user.loc[mean_nbr_ratings_years_minus_one_per_user[\"is_expert\"]==1][\"count_last_year\"]\n",
    "mean_nbr_ratings_years_minus_one_per_user_non_experts=mean_nbr_ratings_years_minus_one_per_user.loc[mean_nbr_ratings_years_minus_one_per_user[\"is_expert\"]==0][\"count_last_year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "\n",
    "color = 'orange'\n",
    "ax1.set_xlabel('Number of ratings per beer in 2015')\n",
    "ax1.set_ylabel('Users count in 2016', color=color)\n",
    "ax1.hist(mean_nbr_ratings_years_minus_one_per_user_non_experts, bins=100, log=True, alpha=0.5, color=\"orange\", label=\"Non experts\")\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid(False)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Users count in 2016', color=color)\n",
    "ax2.hist(mean_nbr_ratings_years_minus_one_per_user_experts, bins=100, log=True, alpha=1, color=color, label=\"Experts\")\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.grid(False)\n",
    "red_patch = mpatches.Patch(color='orange', label='non experts')\n",
    "blue_patch = mpatches.Patch(color='blue', label='experts')\n",
    "ax1.legend(handles=[red_patch, blue_patch])\n",
    "plt.title(\"Distribution of number of ratings per beer in 2015 of users who rated beers in 2016\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this graph, experts are located on the left side of the x-axis, meaning that they rate less popular beer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(mean_nbr_ratings_years_minus_one_per_user_experts,mean_nbr_ratings_years_minus_one_per_user_non_experts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  ttest confirms the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.d) Analysis on the beers styles rated by experts and casuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saké have multiple styles, we just want to take one style for every saké\n",
    "df_ratings_stats['style'] =  df_ratings_stats['style'].str.replace(r'^Saké.*', 'Saké', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numbers of ratings per style\n",
    "ratings_per_style = df_ratings_stats.groupby('style').size().reset_index(name='rating_count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the numbers of rating for the first 16 Beer's Styles with more ratings\n",
    "\n",
    "sorted_ratings = ratings_per_style.sort_values(by='rating_count', ascending=False)\n",
    "\n",
    "top_16_styles = sorted_ratings.head(16)\n",
    "top_16 = top_16_styles['style'].unique()\n",
    "\n",
    "plt.bar(sorted_ratings['style'].head(16), sorted_ratings['rating_count'].head(16))\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel('Beer Styles')\n",
    "plt.ylabel('Rating Count')\n",
    "plt.title('Top 16 Beer Styles by Rating Count')\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let see the evolution over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_per_year = df_ratings_stats.groupby(['style', 'year']).size().reset_index(name='nb_ratings')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_styles_peryear_pivot = df_stats_per_year.pivot(index='style', columns='year', values='nb_ratings')\n",
    "df_styles_peryear_pivot.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This table will show us the number of ratings per year per style for the top16 rated styles (n terms of number of ratings)\n",
    "\n",
    "df_top_16 = df_styles_peryear_pivot.loc[top_16]\n",
    "df_top_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the distribution of the top 16 rated Beer's Styles over time\n",
    "\n",
    "fig, axes = plt.subplots(4,4, figsize = (20,20), sharex = True)\n",
    "bins_ =10\n",
    "\n",
    "\n",
    "years_rating = df_ratings_stats['year'].unique()\n",
    "years_rating = sorted(years_rating)\n",
    "years_rating\n",
    "\n",
    "for i in range(0,4):\n",
    "    for j in range(0,4):\n",
    "        ax = axes[i,j]\n",
    "        current_style = top_16[i + 4 * j]\n",
    "        ax.set_title(current_style) \n",
    "        style_ratings = df_top_16.loc[current_style]\n",
    "        ax.bar(style_ratings.index, style_ratings.values, edgecolor='black')\n",
    "        ax.grid(False)\n",
    "        ax.set_xlabel('Year')\n",
    "        ax.set_ylabel('Number of Ratings')\n",
    "\n",
    "fig.suptitle('Number of Ratings per Year for Top 16 Styles', fontsize=20, y=1.02)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the evolution on time of the number of ratings per style (Plotting Expert and Non Expert evolution)\n",
    "\n",
    "years_ = [year for year in years_rating if year > 2001]\n",
    "n_rows = 4\n",
    "n_cols = 4\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 20), sharex=True)\n",
    "for i, year in enumerate(years_):\n",
    "    \n",
    "    row = i // n_cols\n",
    "    col = i % n_cols\n",
    "    df_expert_year = df_ratings_stat_expert.query('year == @year')\n",
    "    df_ratings_stat_year = df_ratings_stats.query('year == @year')\n",
    "    expert_of_the_year = df_expert_year[df_expert_year.is_expert].user_id\n",
    "    df_expert = df_ratings_stat_year[df_ratings_stat_year['user_id'].isin(expert_of_the_year)]\n",
    "    df_normal = df_ratings_stat_year[~df_ratings_stat_year['user_id'].isin(expert_of_the_year)]\n",
    "    df_stats_per_year_expert = df_expert.groupby(['style', 'year']).size().reset_index(name='nb_ratings')\n",
    "    df_stats_per_year_normal = df_normal.groupby(['style', 'year']).size().reset_index(name='nb_ratings')\n",
    "    df_styles_peryear_pivot_expert = df_stats_per_year_expert.pivot(index='style', columns='year', values='nb_ratings')\n",
    "    df_styles_peryear_pivot_expert.fillna(0, inplace=True)\n",
    "    df_styles_peryear_pivot_normal = df_stats_per_year_normal.pivot(index='style', columns='year', values='nb_ratings')\n",
    "    df_styles_peryear_pivot_normal.fillna(0, inplace=True)\n",
    "    for column in top_16:\n",
    "        if column not in df_styles_peryear_pivot_expert.index:\n",
    "            df_styles_peryear_pivot_expert.loc[column] = 0\n",
    "            df_styles_peryear_pivot_normal.loc[column] = 0\n",
    "    df_top_16_expert = df_styles_peryear_pivot_expert.loc[top_16]\n",
    "    df_top_16_normal = df_styles_peryear_pivot_normal.loc[top_16]\n",
    "    ax = axes[row, col]\n",
    "    ax.plot(df_top_16_normal.index, df_top_16_normal.values, label='Non expert', color='orange')\n",
    "    ax.set_xticks(df_top_16_normal.index,df_top_16_normal.index, rotation=45, ha='right')\n",
    "    ax.set_xlabel('Beer Styles')\n",
    "    ax.set_ylabel('Rating Count (Non experts)', color='black')\n",
    "    ax.tick_params(axis='y', labelcolor='black')\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(df_top_16_expert.index, df_top_16_expert.values, label='Expert', color='blue',alpha=0.3)\n",
    "    ax2.set_ylabel('Rating Count (Expert)', color='blue')\n",
    "    ax2.tick_params(axis='y', labelcolor='blue')\n",
    "    ax.set_title(str(year))\n",
    "    ax.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax.grid(False)\n",
    "    ax2.grid(False)\n",
    "fig.suptitle('Experts and Non experts Ratings Counts for Top 16 Beer Styles by Year', fontsize=20, y=1.02)\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first years we observe that the distribution is similar between the experts and the others. However, the trend changes from year 2010. Since then, experts tend to rate different beers (in terms of style) than non experts. Plus, for certain beers, there are more ratings done by experts than non experts. Let's investigate this last point !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This show us the proportion over time of Expert (Blue) and Non Expert (Orange) rating \n",
    "\n",
    "fig,ax=plt.subplots(4,4,sharex=True)\n",
    "fig.set_size_inches(20,20)\n",
    "n_rows=4\n",
    "n_cols=4\n",
    "for i,style in enumerate(top_16):\n",
    "    df_style=df_ratings_stats.loc[df_ratings_stats[\"style\"]==style].groupby([\"year\",\"is_expert\"])[\"rating\"].agg(\"count\").reset_index()\n",
    "    df_style[\"rating\"]=df_style[\"rating\"]/df_style.groupby(\"year\")[\"rating\"].transform(\"sum\")\n",
    "    df_style.pivot(index=\"year\",columns=\"is_expert\",values=\"rating\").plot(kind=\"bar\",stacked=True,ax=ax[i//n_cols,i%n_cols],color=['orange', 'blue'])\n",
    "\n",
    "    ax[i//n_cols,i%n_cols].set_title(style)\n",
    "    ax[i//n_cols,i%n_cols].set_ylabel(\"Ratings proportion\")\n",
    "    red_patch = mpatches.Patch(color='orange', label='non experts')\n",
    "    blue_patch = mpatches.Patch(color='blue', label='experts')\n",
    "    ax[i//n_cols,i%n_cols].legend(handles=[red_patch, blue_patch])\n",
    "    ax[i//n_cols,i%n_cols].grid(False)\n",
    "    \n",
    "fig.suptitle(\"Rating proportion of experts and non experts for top 16 styles\",fontsize=20,y=1.02)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, even if experts account only for 0.5% of the active they represent a big part in the ratings of the beers. There are even some years and styles for which thew overtake non experts part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus their voice really matter since hey can make a huge difference for the final average rating displayed on websites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It leads us to wonder if their ratings differentiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evolution on time of Experts and non Experts Grades Mean over Styles \n",
    "\n",
    "fig, axs = plt.subplots(4, 4, figsize=(20, 10), sharex = True, sharey = True)\n",
    "axs = axs.flatten()\n",
    "\n",
    "\n",
    "for i, year in enumerate(years_):\n",
    "    df_expert_year = df_ratings_stat_expert.query('year == @year')\n",
    "    df_ratings_stat_year = df_ratings_stats.query('year == @year')\n",
    "    expert_of_the_year = df_expert_year[df_expert_year.is_expert].user_id\n",
    "    df_expert = df_ratings_stat_year[df_ratings_stat_year['user_id'].isin(expert_of_the_year)]\n",
    "    df_normal = df_ratings_stat_year[~df_ratings_stat_year['user_id'].isin(expert_of_the_year)]\n",
    "    ratings_per_style_expert = df_expert.groupby('style')['rating'].mean().reset_index(name='rating_mean')\n",
    "    ratings_per_style_normal = df_normal.groupby('style')['rating'].mean().reset_index(name='rating_mean')\n",
    "    df_stats_per_year_expert = df_expert.groupby(['style', 'year'])['rating'].mean().reset_index(name='ratings_mean')\n",
    "    df_stats_per_year_normal = df_normal.groupby(['style', 'year'])['rating'].mean().reset_index(name='ratings_mean')\n",
    "    df_styles_peryear_pivot_expert = df_stats_per_year_expert.pivot(index='style', columns='year', values='ratings_mean')\n",
    "    df_styles_peryear_pivot_expert.fillna(0, inplace=True)\n",
    "    df_styles_peryear_pivot_normal = df_stats_per_year_normal.pivot(index='style', columns='year', values='ratings_mean')\n",
    "    df_styles_peryear_pivot_normal.fillna(0, inplace=True)\n",
    "    for column in top_16:\n",
    "        if column not in df_styles_peryear_pivot_expert.index:\n",
    "            df_styles_peryear_pivot_expert.loc[column] = 0\n",
    "            df_styles_peryear_pivot_normal.loc[column] = 0\n",
    "    df_top_16_expert = df_styles_peryear_pivot_expert.loc[top_16]\n",
    "    df_top_16_normal = df_styles_peryear_pivot_normal.loc[top_16]\n",
    "\n",
    "   \n",
    "    ax = axs[i]\n",
    "\n",
    "    ax.plot(df_top_16_expert.index, df_top_16_expert.values, label='Expert')\n",
    "    ax.plot(df_top_16_normal.index, df_top_16_normal.values, label='Normal')\n",
    "    ax.set_xticks(range(len(top_16)))\n",
    "    ax.set_xticklabels(top_16, rotation=45, ha='right')\n",
    "    ax.set_xlabel('Beer Styles')\n",
    "    ax.set_ylabel('Rating ')\n",
    "    ax.set_title('Top 16 Styles in Graded Beer Styles in ' + str(year))\n",
    "    ax.legend()\n",
    "    ax.grid(False)\n",
    "fig.suptitle('Experts and Non experts Ratings Means for Top 16 Rated Beer Styles by Year', fontsize=20, y=1.02)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that experts and non experts have similar behaviour on the most rated beer styles. Hence, we can say that highly-popular beers makers can work regardless of a side-effect of experts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.e) Now let's analyse how their ratings differentiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the difference of ratings between experts and non experts for each beer (median)\n",
    "minimum_number_of_ratings=100\n",
    "YEAR=2017\n",
    "absolute_difference_ratings=[]\n",
    "\n",
    "df_ratings_this_year,experts_id=filter_year_and_add_is_expert(df_ratings_stats,YEAR,df_ratings_stat_expert)\n",
    "beers_with_enough_ratings=df_ratings_this_year.groupby(\"beer_id\").agg(\"size\").loc[df_ratings_this_year.groupby(\"beer_id\").agg(\"size\")>minimum_number_of_ratings].index.values\n",
    "df_advocate_ratings_this_year_with_enough_ratings=df_ratings_this_year.loc[df_ratings_this_year[\"beer_id\"].isin(beers_with_enough_ratings)]\n",
    "difference_ratings_medians=df_advocate_ratings_this_year_with_enough_ratings.groupby([\"beer_id\",\"is_expert\"])[\"rating\"].agg(\"median\")\n",
    "\n",
    "for beer_id in difference_ratings_medians.index.get_level_values(0).unique():\n",
    "    if 0 in difference_ratings_medians.loc[beer_id] and 1 in difference_ratings_medians.loc[beer_id]:\n",
    "        absolute_difference_ratings.append(np.abs(difference_ratings_medians.loc[beer_id,0]-difference_ratings_medians.loc[beer_id,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the difference of ratings between experts and non experts for each beer (median)\n",
    "plt.hist(absolute_difference_ratings,bins=50)\n",
    "plt.xlabel(\"Absolute difference in median ratings\")\n",
    "plt.ylabel(\"Number of beers\")\n",
    "plt.title(f\"Distribution of absolute difference in median ratings between experts and non experts \\n for beers with more than {minimum_number_of_ratings} ratings in {YEAR}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the difference of ratings between experts and non experts for each beer (mean and median)\n",
    "fig,ax=plt.subplots(int(np.ceil(len(np.arange(50,500,50))/3)),3,sharex=True)\n",
    "fig.set_size_inches(20,20)\n",
    "nb_bins=20\n",
    "\n",
    "for i,minimum_number_of_ratings in enumerate(np.arange(50,500,50)):\n",
    "    difference_ratings_medians_list=[]\n",
    "    difference_ratings_means_list=[]\n",
    "    beers_with_enough_ratings=df_ratings_this_year.groupby(\"beer_id\").agg(\"size\").loc[df_ratings_this_year.groupby(\"beer_id\").agg(\"size\")>minimum_number_of_ratings].index.values\n",
    "    df_advocate_ratings_this_year_with_enough_ratings=df_ratings_this_year.loc[df_ratings_this_year[\"beer_id\"].isin(beers_with_enough_ratings)]\n",
    "    difference_ratings_medians=df_advocate_ratings_this_year_with_enough_ratings.groupby([\"beer_id\",\"is_expert\"])[\"rating\"].agg(\"median\")\n",
    "    difference_ratings_means=df_advocate_ratings_this_year_with_enough_ratings.groupby([\"beer_id\",\"is_expert\"])[\"rating\"].agg(\"mean\")\n",
    "    \n",
    "    for beer_id in difference_ratings_medians.index.get_level_values(0).unique():\n",
    "        if 0 in difference_ratings_medians.loc[beer_id] and 1 in difference_ratings_medians.loc[beer_id]:\n",
    "            difference_ratings_medians_list.append(difference_ratings_medians.loc[beer_id,1]-difference_ratings_medians.loc[beer_id,0])\n",
    "            difference_ratings_means_list.append(difference_ratings_means.loc[beer_id,1]-difference_ratings_means.loc[beer_id,0])\n",
    "    if i==0:\n",
    "        difference_means_to_test=difference_ratings_means_list.copy()\n",
    "    ax[i//3,i%3].hist(difference_ratings_medians_list,alpha=0.5,bins=nb_bins,color=\"b\",label=\"median\")\n",
    "    ax[i//3,i%3].hist(difference_ratings_means_list,alpha=0.5,bins=nb_bins,color=\"orange\",label=\"mean\")\n",
    "    ax[i//3,i%3].axvline(0,c=\"r\",linestyle=\"--\")\n",
    "    ax[i//3,i%3].set_xlabel(\"difference in medians/means ratings (experts-non experts)\")\n",
    "    ax[i//3,i%3].set_ylabel(\"Number of beers\")\n",
    "    ax[i//3,i%3].set_title(\"Minimum number of ratings: \"+str(minimum_number_of_ratings))\n",
    "    ax[i//3,i%3].legend()\n",
    "fig.suptitle(\"Distribution of difference in median and mean ratings of experts - non experts for different minimum number of ratings of beers\",fontsize=15,y=1.02)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see that the experts tend to be more severe (negative difference), lets check if this trend holds for all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the distribution of the difference of ratings between experts and non experts over all beers (mean and median) for each year\n",
    "fig,ax=plt.subplots(4,3,sharex=True)\n",
    "fig.set_size_inches(20,20)\n",
    "nb_bins=20\n",
    "min_number_of_ratings=50\n",
    "\n",
    "for i,YEAR in enumerate(range(2006,2018)):\n",
    "  \n",
    "    difference_ratings_medians_list=[]\n",
    "    difference_ratings_means_list=[]\n",
    "    df_ratings_this_year,experts_id=filter_year_and_add_is_expert(df_ratings_stats,YEAR,df_ratings_stat_expert)\n",
    "    beers_with_enough_ratings=df_ratings_this_year.groupby(\"beer_id\").agg(\"size\").loc[df_ratings_this_year.groupby(\"beer_id\").agg(\"size\")>min_number_of_ratings].index.values\n",
    "    df_advocate_ratings_this_year_with_enough_ratings=df_ratings_this_year.loc[df_ratings_this_year[\"beer_id\"].isin(beers_with_enough_ratings)]\n",
    "    difference_ratings_medians=df_advocate_ratings_this_year_with_enough_ratings.groupby([\"beer_id\",\"is_expert\"])[\"rating\"].agg(\"median\")\n",
    "    difference_ratings_means=df_advocate_ratings_this_year_with_enough_ratings.groupby([\"beer_id\",\"is_expert\"])[\"rating\"].agg(\"mean\")\n",
    "    \n",
    "    for beer_id in difference_ratings_medians.index.get_level_values(0).unique():\n",
    "        if 0 in difference_ratings_medians.loc[beer_id] and 1 in difference_ratings_medians.loc[beer_id]:\n",
    "            difference_ratings_medians_list.append(difference_ratings_medians.loc[beer_id,1]-difference_ratings_medians.loc[beer_id,0])\n",
    "            difference_ratings_means_list.append(difference_ratings_means.loc[beer_id,1]-difference_ratings_means.loc[beer_id,0])\n",
    "            \n",
    "    ax[i//3,i%3].hist(difference_ratings_medians_list,alpha=0.5,bins=nb_bins,color=\"b\",label=\"median\")\n",
    "    ax[i//3,i%3].hist(difference_ratings_means_list,alpha=0.5,bins=nb_bins,color=\"orange\",label=\"mean\")\n",
    "    ax[i//3,i%3].axvline(0,c=\"r\",linestyle=\"--\")\n",
    "    ax[i//3,i%3].set_xlim(-1.25,1)\n",
    "    ax[i//3,i%3].set_xlabel(\"Difference in median ratings (experts-non experts)\")\n",
    "    ax[i//3,i%3].set_ylabel(\"Number of beers\")\n",
    "    ax[i//3,i%3].set_title(\"Year: \"+str(YEAR))\n",
    "    ax[i//3,i%3].legend()\n",
    "fig.suptitle(f\"Distribution of difference in median and mean ratings between (experts - non experts) for different years and minimum number of ratings of beers: {min_number_of_ratings}\",fontsize=15,y=1.02)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the trend is not that obvious now, grouping the results by beer show that we cannot say that in average experts are more severe (on beers that have at least 50 ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same but with beer that have at least 400 ratings (popular beers)\n",
    "fig,ax=plt.subplots(4,3,sharex=True)\n",
    "fig.set_size_inches(20,20)\n",
    "nb_bins=20\n",
    "min_number_of_ratings=400\n",
    "\n",
    "for i,YEAR in enumerate(range(2006,2018)):\n",
    "    difference_ratings_medians_list=[]\n",
    "    difference_ratings_means_list=[]\n",
    "    df_ratings_this_year,experts_id=filter_year_and_add_is_expert(df_ratings_stats,YEAR,df_ratings_stat_expert)\n",
    "    beers_with_enough_ratings=df_ratings_this_year.groupby(\"beer_id\").agg(\"size\").loc[df_ratings_this_year.groupby(\"beer_id\").agg(\"size\")>min_number_of_ratings].index.values\n",
    "    df_advocate_ratings_this_year_with_enough_ratings=df_ratings_this_year.loc[df_ratings_this_year[\"beer_id\"].isin(beers_with_enough_ratings)]\n",
    "    difference_ratings_medians=df_advocate_ratings_this_year_with_enough_ratings.groupby([\"beer_id\",\"is_expert\"])[\"rating\"].agg(\"median\")\n",
    "    difference_ratings_means=df_advocate_ratings_this_year_with_enough_ratings.groupby([\"beer_id\",\"is_expert\"])[\"rating\"].agg(\"mean\")\n",
    "    \n",
    "    for beer_id in difference_ratings_medians.index.get_level_values(0).unique():\n",
    "        if 0 in difference_ratings_medians.loc[beer_id] and 1 in difference_ratings_medians.loc[beer_id]:\n",
    "            difference_ratings_medians_list.append(difference_ratings_medians.loc[beer_id,1]-difference_ratings_medians.loc[beer_id,0])\n",
    "            difference_ratings_means_list.append(difference_ratings_means.loc[beer_id,1]-difference_ratings_means.loc[beer_id,0])\n",
    "            \n",
    "    ax[i//3,i%3].hist(difference_ratings_medians_list,alpha=0.5,bins=nb_bins,color=\"b\",label=\"median\")\n",
    "    ax[i//3,i%3].hist(difference_ratings_means_list,alpha=0.5,bins=nb_bins,color=\"orange\",label=\"mean\")\n",
    "    ax[i//3,i%3].axvline(0,c=\"r\",linestyle=\"--\")\n",
    "    ax[i//3,i%3].set_xlim(-1.25,1)\n",
    "    ax[i//3,i%3].set_xlabel(\"Difference in median ratings (experts-non experts)\")\n",
    "    ax[i//3,i%3].set_ylabel(\"Number of beers\")\n",
    "    ax[i//3,i%3].set_title(\"Year: \"+str(YEAR))\n",
    "    ax[i//3,i%3].legend()\n",
    "fig.suptitle(f\"Distribution of difference in median and mean ratings between (experts - non experts) for different years and minimum number of ratings of beers: {min_number_of_ratings}\",fontsize=15,y=1.02)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With beers that have at least 400 ratings (the year of the analysis), the results seem different since the distribution of the mean difference (orange) is denser in the negative values, it invites us to imagine that experts are more severe on popular beers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.f) Analysis of the ratings for specific beers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We analyse only ratings from Year 2016\n",
    "YEAR=2016\n",
    "df_ratings_this_year,experts_id=filter_year_and_add_is_expert(df_ratings_stats,YEAR,df_ratings_stat_expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of some ratings for experts and non experts for different beers\n",
    "nrows=4\n",
    "fig,ax=plt.subplots(nrows,nrows)\n",
    "fig.set_size_inches(4*nrows,4*nrows)\n",
    "minimum_number_of_ratings=400\n",
    "bins=10\n",
    "for i in range(nrows*nrows):\n",
    "    np.random.seed(i)\n",
    "    beer_id_to_study=np.random.choice(df_ratings_this_year.groupby(\"beer_id\").agg(\"size\").loc[df_ratings_this_year.groupby(\"beer_id\").agg(\"size\")>minimum_number_of_ratings].index.values)\n",
    "    ratings_this_beer=df_ratings_this_year.loc[df_ratings_this_year[\"beer_id\"]==beer_id_to_study]\n",
    "    ratings_this_beer_experts=ratings_this_beer.loc[ratings_this_beer[\"is_expert\"]==1]\n",
    "    ratings_this_beer_non_experts=ratings_this_beer.loc[ratings_this_beer[\"is_expert\"]==0]\n",
    "    while len(ratings_this_beer_experts)==0 or len(ratings_this_beer_non_experts)==0:\n",
    "        beer_id_to_study=np.random.choice(df_ratings_this_year.groupby(\"beer_id\").agg(\"size\").loc[df_ratings_this_year.groupby(\"beer_id\").agg(\"size\")>minimum_number_of_ratings].index.values)\n",
    "        ratings_this_beer=df_ratings_this_year.loc[df_ratings_this_year[\"beer_id\"]==beer_id_to_study]\n",
    "        ratings_this_beer_experts=ratings_this_beer.loc[ratings_this_beer[\"is_expert\"]==1]\n",
    "        ratings_this_beer_non_experts=ratings_this_beer.loc[ratings_this_beer[\"is_expert\"]==0]\n",
    "\n",
    "    \n",
    "    difference_ttest=ttest_ind(ratings_this_beer_experts[\"rating\"],ratings_this_beer_non_experts[\"rating\"])\n",
    "    ax2 = ax[i//nrows,i%nrows].twinx()\n",
    "    ax2.hist(ratings_this_beer_experts[\"rating\"],bins=bins,alpha=0.3,label=\"Experts\",color=\"b\")\n",
    "    ax[i//nrows,i%nrows].hist(ratings_this_beer_non_experts[\"rating\"],bins=bins,alpha=0.5,label=\"Non experts\",color=\"orange\")\n",
    "    ax[i//nrows,i%nrows].axvline(ratings_this_beer_experts[\"rating\"].mean(),c=\"b\",linestyle=\"--\")\n",
    "    ax[i//nrows,i%nrows].axvline(ratings_this_beer_non_experts[\"rating\"].mean(),c=\"orange\",linestyle=\"--\")\n",
    "    \n",
    "    ax[i//nrows,i%nrows].set_xticks(np.arange(0,6,1),labels=np.arange(0,6,1))\n",
    "    ax[i//nrows,i%nrows].set_xlabel(\"Rating\")\n",
    "    ax[i//nrows,i%nrows].set_ylabel(\"Count (Non experts)\",color=\"orange\")\n",
    "    ax2.set_ylabel(\"Count (experts)\",color=\"b\")\n",
    "    ax[i//nrows, i%nrows].set_title(f\"Beer id: {beer_id_to_study} Nbr of ratings: {ratings_this_beer.shape[0]}\\n ttest diff, stat: {np.round(difference_ttest[0], 2)}, pvalue: {np.round(difference_ttest[1], 2)}\")\n",
    "    if i%nrows==0:\n",
    "        ax[i//nrows,i%nrows].legend()\n",
    "        ax2.legend(loc='center left')\n",
    "\n",
    "\n",
    "\n",
    "fig.suptitle(f\"Distribution of some ratings for experts and non experts for year {YEAR}\",y=1.01,fontsize=20)\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that for many beers, the difference of ratings is significant. Plus, experts seem not very likely to give excelent ratings (4.5 to 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should investigate the last point for later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.g) Ratings at the beginning of a beer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyse ratings of a specific beer over time\n",
    "def make_analysis_one_beer(beer_id_to_study):\n",
    "    ratings_this_beer=df_ratings_stats.loc[df_ratings_stats[\"beer_id\"]==beer_id_to_study]\n",
    "    ratings_this_beer.sort_values(by=\"date\",inplace=True)\n",
    "    ratings_this_beer[\"is_expert\"]=ratings_this_beer[[\"user_id\",\"year\"]].apply(lambda x: 1 if x[\"user_id\"] in experts_dict[x[\"year\"]] else 0,axis=1)\n",
    "    # group ratings by date and count the number of ratings for each date\n",
    "    ratings_by_date = ratings_this_beer.groupby(['date','is_expert']).size().reset_index(name='count')\n",
    "\n",
    "\n",
    "    # calculate the cumulative sum of the ratings\n",
    "    ratings_by_date['cumulative_count'] = ratings_by_date['count'].cumsum()\n",
    "\n",
    "    fig,ax=plt.subplots(1,2)\n",
    "    fig.set_size_inches(20,10)\n",
    "    # plot the evolution of the cumulative number of ratings over time\n",
    "    n=0\n",
    "    old_date=ratings_by_date[\"date\"].values[0]\n",
    "    for i,rating in ratings_by_date.iterrows():\n",
    "        if rating[\"is_expert\"]==1:\n",
    "            c=\"b\"\n",
    "            markersize=2\n",
    "        else:\n",
    "            c=\"orange\"\n",
    "            markersize=1\n",
    "        ax[0].plot([old_date,rating[\"date\"]],[n,rating[\"cumulative_count\"]],marker=\"o\",c=c,markersize=markersize)\n",
    "        n=rating[\"cumulative_count\"]\n",
    "        old_date=rating[\"date\"]\n",
    "        \n",
    "    fontsize_x_tiks=16\n",
    "    ax[0].set_xlabel('Date',fontsize=fontsize_x_tiks)\n",
    "    ax[0].set_ylabel('Cumulative number of ratings',fontsize=fontsize_x_tiks)\n",
    "    last_year=ratings_this_beer[\"year\"].values[-1]\n",
    "    first_year=ratings_this_beer[\"year\"].values[0]\n",
    "    xticks = np.array([pd.to_datetime(str(year), format='%Y') for year in range(first_year,last_year+1)])\n",
    "    if len(xticks)>5:\n",
    "        indexs_x_ticks=np.arange(0,len(xticks),len(xticks)//5)\n",
    "        indexs_x_ticks=np.floor(indexs_x_ticks).astype(int)\n",
    "        ax[0].set_xticks(xticks[indexs_x_ticks])\n",
    "    else:\n",
    "        ax[0].set_xticks(xticks)\n",
    "    \n",
    "    red_patch = mpatches.Patch(color='orange', label='non experts')\n",
    "    blue_patch = mpatches.Patch(color='blue', label='experts')\n",
    "    ax[0].legend(handles=[red_patch, blue_patch],fontsize=16)\n",
    "    \n",
    "    ratings_this_beer.groupby(\"year\")[\"rating\"].agg(\"mean\").plot(ax=ax[1],marker=\"o\",c=\"r\",markersize=5,linestyle=\"--\",label=\"mean rating experts\")\n",
    "    ax[1].set_xlabel('Year',fontsize=fontsize_x_tiks)\n",
    "    ax[1].set_ylabel('Mean rating of the year',fontsize=fontsize_x_tiks)\n",
    "    fig.suptitle(f'Evolution of cumulative number of ratings over time for beer {beer_id_to_study}',fontsize=20)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_analysis_one_beer(\"ba_4054\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we observe that in 2004 a non expert made a poor rating on this beer (about 1). However from 2008 to 2012, 3 experts rated this beer with a better grade (between 2.5 and 3). Then some experts and non experts rated this beer more often and with a better grade. We may imagine that experts played a key role in that case. By their early ratings they encouraged other raters to taste and rate this beer and for the last year (2017, which is the last year of our dataset), the grade was much higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_analysis_one_beer(\"rb_95399\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the situation is different, and the previous interpretation cannot be made. The situation is specfic to each beer. We should investigate those behaviours for P3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let see where the ratings come from, for different beers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyse ratings of a different beers over time\n",
    "n_rows=4\n",
    "\n",
    "fig,ax=plt.subplots(n_rows,n_rows)\n",
    "fig.set_size_inches(4*n_rows,4*n_rows)\n",
    "for k in range(n_rows*n_rows):\n",
    "    if k==0:\n",
    "        beer_id_to_study=\"ba_27500\"\n",
    "    else:\n",
    "        beer_id_to_study=df_ratings_stats.sample(1)[\"beer_id\"].values[0]\n",
    "    ratings_this_beer=df_ratings_stats.loc[df_ratings_stats[\"beer_id\"]==beer_id_to_study]\n",
    "    ratings_this_beer.sort_values(by=\"date\",inplace=True)\n",
    "    ratings_this_beer[\"is_expert\"]=ratings_this_beer[[\"user_id\",\"year\"]].apply(lambda x: 1 if x[\"user_id\"] in experts_dict[x[\"year\"]] else 0,axis=1)\n",
    "    # group ratings by date and count the number of ratings for each date\n",
    "    ratings_by_date = ratings_this_beer.groupby(['date','is_expert']).size().reset_index(name='count')\n",
    "\n",
    "\n",
    "    # calculate the cumulative sum of the ratings\n",
    "    ratings_by_date['cumulative_count'] = ratings_by_date['count'].cumsum()\n",
    "\n",
    "    # plot the evolution of the cumulative number of ratings over time\n",
    "    n=0\n",
    "    old_date=ratings_by_date[\"date\"].values[0]\n",
    "   \n",
    "    for i,rating in ratings_by_date.iterrows():\n",
    "       \n",
    "        if rating[\"is_expert\"]==1:\n",
    "            c=\"b\"\n",
    "            markersize=2\n",
    "            \n",
    "        else:\n",
    "            c=\"orange\"\n",
    "            markersize=0.5\n",
    "            \n",
    "        ax[k//n_rows,k%n_rows].plot([old_date,rating[\"date\"]],[n,rating[\"cumulative_count\"]],marker=\"o\",c=c,markersize=markersize)\n",
    "       \n",
    "        n=rating[\"cumulative_count\"]\n",
    "        old_date=rating[\"date\"]\n",
    "    ax[k//n_rows,k%n_rows].set_xlabel('Date')\n",
    "    ax[k//n_rows,k%n_rows].set_ylabel('Cumulative number of ratings')\n",
    "    last_year=ratings_this_beer[\"year\"].values[-1]\n",
    "    first_year=ratings_this_beer[\"year\"].values[0]\n",
    "    xticks = np.array([pd.to_datetime(str(year), format='%Y') for year in range(first_year,last_year+1)])\n",
    "    if len(xticks)>3:\n",
    "        indexs_x_ticks=np.arange(0,len(xticks),len(xticks)//3)\n",
    "        indexs_x_ticks=np.floor(indexs_x_ticks).astype(int)\n",
    "        ax[k//n_rows,k%n_rows].set_xticks(xticks[indexs_x_ticks])\n",
    "    else:\n",
    "        ax[k//n_rows,k%n_rows].set_xticks(xticks)\n",
    "    ax[k//n_rows,k%n_rows].set_title(f'Beer id: {beer_id_to_study}')\n",
    "    red_patch = mpatches.Patch(color='orange', label='non experts')\n",
    "    blue_patch = mpatches.Patch(color='blue', label='experts')\n",
    "    ax[k//n_rows,k%n_rows].legend(handles=[red_patch, blue_patch])\n",
    "\n",
    "fig.suptitle(f'Evolution of cumulative number of ratings over time for 25 beers',y=1.01,fontsize=20)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While representing only 0.5% of active users, experts account for a lot in the beer ratings. Also It seems that for some beers, they represent a massive proportion of all ratings (especially for beer that do not have a lot of ratings).\n",
    "We should try to find a correspondance beetween the popularity of the beers (number over ratings) and the proportion  of ratings done by the experts at the beginning. We will tackle this issue for the next milestone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.h) Evolution of ratings over time, impact of the experts, bis \n",
    "#### Try to find beers which have been rated by expert and non experts at different years in order to identify if an expert tends to influence the ratings or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column 'group_size' to the DataFrame, representing the size of each group defined by 'beer_id', 'year', and 'is_expert'\n",
    "df_ratings_stats['group_size'] = df_ratings_stats.groupby(['beer_id', 'year', 'is_expert'])['rating'].transform('size')\n",
    "\n",
    "# In order to build confident intervals we need at least 10 ratings per beer\n",
    "df_ratings_stat_filtered = df_ratings_stats[df_ratings_stats['group_size'] >= 10].drop(columns='group_size')\n",
    "\n",
    "# Calculate the number of rows with is_expert = 1 for each beer_id\n",
    "expert_counts = df_ratings_stat_filtered[df_ratings_stat_filtered['is_expert'] == 1].groupby('beer_id')['is_expert'].sum()\n",
    "\n",
    "# Sort the results in descending order and select the top 16\n",
    "top_beer_ids = expert_counts.sort_values(ascending=False).head(16).index.tolist()\n",
    "\n",
    "result_df = df_ratings_stat_filtered[df_ratings_stat_filtered['beer_id'].isin(top_beer_ids)][['beer_id', 'beer_name']].drop_duplicates(subset=['beer_id'])\n",
    "\n",
    "beer_ids_to_study, beer_names_to_study = result_df['beer_id'].to_list(), result_df['beer_name'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beer_ids_to_study, beer_names_to_study = zip(*df_ratings_stat_filtered[['beer_id', 'beer_name']].value_counts()[:16].index)\n",
    "\n",
    "# Create a 4x4 subplot grid\n",
    "fig, axes = plt.subplots(4, 4, figsize=(20, 20))\n",
    "\n",
    "# Flatten the 2D array of axes to iterate over it easily\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate over beer_ids and corresponding subplots\n",
    "for i, (beer_id_to_study, beer_name_to_study) in enumerate(zip(beer_ids_to_study, beer_names_to_study)):\n",
    "    # Select ratings for the current beer_id\n",
    "    ratings_this_beer = df_ratings_stat_filtered.loc[df_ratings_stat_filtered[\"beer_id\"] == beer_id_to_study]\n",
    "    # Expert CI\n",
    "    ratings_this_beer_experts = ratings_this_beer[ratings_this_beer['is_expert'] == 1]\n",
    "    ratings_this_beer_experts = ratings_this_beer_experts.groupby([\"year\"])[\"rating\"].agg([\"std\",\"mean\",\"count\"]).reset_index()\n",
    "    ratings_this_beer_experts['CI95_up'] = ratings_this_beer_experts.apply(lambda x: x[\"mean\"] + 1.96 * x[\"std\"] / np.sqrt(x[\"count\"]), axis=1)\n",
    "    ratings_this_beer_experts['CI95_down'] = ratings_this_beer_experts.apply(lambda x: x[\"mean\"] - 1.96 * x[\"std\"] / np.sqrt(x[\"count\"]), axis=1) \n",
    "    # Casual CI\n",
    "    ratings_this_beer_casuals = ratings_this_beer[ratings_this_beer['is_expert'] == 0]\n",
    "    ratings_this_beer_casuals = ratings_this_beer_casuals.groupby([\"year\"])[\"rating\"].agg([\"std\",\"mean\",\"count\"]).reset_index()\n",
    "    ratings_this_beer_casuals['CI95_up'] = ratings_this_beer_casuals.apply(lambda x: x[\"mean\"] + 1.96 * x[\"std\"] / np.sqrt(x[\"count\"]), axis=1)\n",
    "    ratings_this_beer_casuals['CI95_down'] = ratings_this_beer_casuals.apply(lambda x: x[\"mean\"] - 1.96 * x[\"std\"] / np.sqrt(x[\"count\"]), axis=1) \n",
    "    # Plot on the current subplot\n",
    "    lineplot_expert = sns.lineplot(data=ratings_this_beer_experts, x='year', y='mean', label='Expert', ax=axes[i], color='blue')\n",
    "    lineplot_casual = sns.lineplot(data=ratings_this_beer_casuals, x='year', y='mean', label='Casual', ax=axes[i], color='red')\n",
    "    \n",
    "    # Fill between the confidence intervals\n",
    "    axes[i].fill_between(ratings_this_beer_experts['year'], ratings_this_beer_experts['CI95_down'], ratings_this_beer_experts['CI95_up'], \n",
    "                         color='blue', alpha=0.2)\n",
    "\n",
    "    axes[i].fill_between(ratings_this_beer_casuals['year'], ratings_this_beer_casuals['CI95_down'], ratings_this_beer_casuals['CI95_up'], \n",
    "                         color='red', alpha=0.2)\n",
    "\n",
    "    axes[i].set(xlabel=None, ylabel=None)\n",
    "    axes[i].set_title(f'Beer id: {beer_id_to_study}, name: {beer_name_to_study}')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlim(2000, 2018)\n",
    "    ax.set_ylim(1, 5)  \n",
    " \n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig.text(0.5,0, \"Year\", fontsize=16)\n",
    "fig.text(0,0.5, \"Average rating\", rotation = 90, fontsize=16)\n",
    "fig.suptitle('Top 16 most rated beers by expert - Average ratings for expert and casuals, with 95% CI', fontsize=20,y=1.01)\n",
    "# Adjust layout to prevent overlapping\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the top 16 most rated beers (for experts), the plots illustrate that the expert ratings fluctuate more (confident interval are much bigger) than the ratings of the casuals , which tend to be more stable. We can also notice that the expert curve is almost everytime below the non-experts one, which means that the expert are more likely to be more strict about the grade of a beer. Another point is that the experts start giving rating after the casual ones and initially give a grade which is much smaller than casuals. However, the ratings of expert and casual tend to be much more closer to each other over the years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A next step should be to do the same kind of analysis on beers that do not have a lot of ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 2 Textual analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Process datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textual_analysis import *\n",
    "from visualization import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Very long to run, results saved in pkl files\n",
    "df_texts = create_text_dataset(df_adv_reviews,df_rb_reviews,df_all_users,experts_dict)\n",
    "df_texts_experts, df_texts_others = compute_text_stats(df_texts=df_texts)\n",
    "\n",
    "save_pickle(df_texts, '../datas/df_texts.pkl')\n",
    "save_pickle(df_texts_experts, '../datas/df_texts_experts.pkl')\n",
    "save_pickle(df_texts_others, '../datas/df_texts_others.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed reviews\n",
    "df_texts_expert = load_pickle('../datas/processed/df_texts_experts.pkl')\n",
    "df_texts_casual = load_pickle('../datas/processed/df_texts_others.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase all texts\n",
    "df_texts_expert.text = df_texts_expert.text.str.lower()\n",
    "df_texts_casual.text = df_texts_casual.text.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2528420, 5450345)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_texts_expert), len(df_texts_casual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts_casual_reduced = df_texts_casual.sample(len(df_texts_expert), random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2528420, 2528420)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_texts_expert), len(df_texts_casual_reduced)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 30.43it/s]\n"
     ]
    }
   ],
   "source": [
    "# Yannis\n",
    "df_expert_tokens = tokenize(df_texts_expert)\n",
    "save_pickle(df_expert_tokens, '../datas/processed/df_expert_tokens.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vincent\n",
    "df_casual_tokens = tokenize(df_texts_casual_reduced)\n",
    "save_pickle(df_casual_tokens, '../datas/processed/df_casual_tokens.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Compute most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts_experts['nb_reviews'] = df_texts_experts.groupby('user_id')['user_id'].transform('size')\n",
    "df_texts_others['nb_reviews'] = df_texts_others.groupby('user_id')['user_id'].transform('size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words_experts = compute_top_words(df_texts_experts_lemmatized)\n",
    "plot_top_words(top_words_experts, 'Experts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words_others = compute_top_words(df_texts_others_lemmatized)\n",
    "plot_top_words(top_words_others, 'Others')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts_others_sentiment = sentiment(df_texts_others_lemmatized)\n",
    "df_texts_experts_sentiment = sentiment(df_texts_experts_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts_experts_sentiment[['nb_words','Neg_sentiment','Neu_sentiment','Pos_sentiment','Comp_sentiment']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts_others_sentiment[['nb_words','Neg_sentiment','Neu_sentiment','Pos_sentiment','Comp_sentiment']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Statistical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Number of words per review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the number of words in the reviews between experts and non experts\n",
    "ttest_rel(df_texts_experts_sentiment['nb_words'],df_texts_others_sentiment['nb_words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the compund sentiment between experts and non experts\n",
    "ttest_rel(df_texts_experts_sentiment['Comp_sentiment'], df_texts_others_sentiment['Comp_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the negative sentiment between experts and non experts\n",
    "ttest_rel(df_texts_experts_sentiment['Neg_sentiment'], df_texts_others_sentiment['Neg_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the positive sentiment between experts and non experts\n",
    "ttest_rel(df_texts_experts_sentiment['Pos_sentiment'], df_texts_others_sentiment['Pos_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the neutral sentiment between experts and non experts\n",
    "ttest_rel(df_texts_experts_sentiment['Neu_sentiment'], df_texts_others_sentiment['Neu_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = \"Your sample text goes here. text goes You can text goes replace this with your own text.\"\n",
    "text += \"Your sample text goes here. text goes You can text goes replace this with your own text.\"\n",
    "text += \"Your sample text goes here. text goes You can text goes replace this with your own text.\"\n",
    "text += \"Your sample text goes here. text goes You can text goes replace this with your own text.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common bigram: [(('text', 'goes'), 12)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(100000):\n",
    "    # Sample text\n",
    "    \n",
    "\n",
    "    # Tokenize the text into words\n",
    "    words = word_tokenize(text)\n",
    "\n",
    "    # Generate bigrams\n",
    "    bi_grams = list(bigrams(words))\n",
    "\n",
    "    # Count the frequency of each bigram\n",
    "    bi_gram_counts = Counter(bi_grams)\n",
    "\n",
    "    # Find the most common bigram\n",
    "    most_common_bigram = bi_gram_counts.most_common(1)\n",
    "\n",
    "print(\"Most common bigram:\", most_common_bigram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text += \"Your sample text goes here. text goes You can text goes replace this with your own text.\"\n",
    "\n",
    "len(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
