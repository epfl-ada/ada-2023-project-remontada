{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# -*- author : Vincent Roduit - Yannis Laaroussi - Fabio Palmisano - Vincent Roh - Alexi Semiz -*-\n",
    "# -*- date : 2023-11-15 -*-\n",
    "# -*- Last revision: 2023-11-15 -*-\n",
    "# -*- python version : 3.9.13 -*-\n",
    "# -*- Description: Main Containing all the meaningfull results -*-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from copy import deepcopy\n",
    "from statsmodels.stats import diagnostic\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from scipy.stats import ttest_ind\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import functions\n",
    "from read.read_functions import read_txt\n",
    "from read.pickle_functions import *\n",
    "from create_all_users import create_all_users\n",
    "from create_rating_statistic import create_ratings_stat\n",
    "from create_all_beers import *\n",
    "\n",
    "#import cleaning functions\n",
    "from cleaning_functions.matched_beer import *\n",
    "from cleaning_functions.rate_beer import *\n",
    "from cleaning_functions.advocate import *\n",
    "\n",
    "#import functions for the analysis\n",
    "from compute_experts import *\n",
    "\n",
    "#import functions for text analysis\n",
    "from textual_analysis import detect_language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Download and save datas\n",
    "### Data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data paths for raw files\n",
    "beer_advocate_path = '../datas/BeerAdvocate/'\n",
    "matched_beer_data_path = '../datas/matched_beer_data/'\n",
    "rate_beer_path = '../datas/RateBeer/'\n",
    "\n",
    "advocate_beers_path = beer_advocate_path + 'beers.csv'\n",
    "advovate_breweries_path = beer_advocate_path + 'breweries.csv'\n",
    "advocate_ratings_path = beer_advocate_path + 'ratings.txt'\n",
    "advocate_reviews_path = beer_advocate_path + 'reviews.txt'\n",
    "advocate_users_path = beer_advocate_path + 'users.csv'\n",
    "\n",
    "matched_beer_beers = matched_beer_data_path + 'beers.csv'\n",
    "matched_beer_breweries = matched_beer_data_path + 'breweries.csv'\n",
    "matched_beer_ratings_ba = matched_beer_data_path + 'ratings_ba.txt'\n",
    "matched_beer_ratings_rb = matched_beer_data_path + 'ratings_rb.txt'\n",
    "matched_beer_ratings = matched_beer_data_path + 'ratings.csv'\n",
    "matched_beer_users_approx = matched_beer_data_path + 'users_approx.csv'\n",
    "matched_beer_users = matched_beer_data_path + 'users.csv'\n",
    "\n",
    "rate_beer_beers = rate_beer_path + 'beers.csv'\n",
    "rate_beer_breweries = rate_beer_path + 'breweries.csv'\n",
    "rate_beer_users = rate_beer_path + 'users.csv'\n",
    "rate_beer_ratings = rate_beer_path + 'ratings.txt'\n",
    "rate_beer_reviews = rate_beer_path + 'reviews.txt'\n",
    "\n",
    "contries_path = '../datas/countries/countries.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data paths for pickle files\n",
    "beer_advocate_path_pickle = '../datas/BeerAdvocate/pickles/df_advocate_'\n",
    "matched_beer_data_path_pickle = '../datas/matched_beer_data/pickles/df_matched_beer_'\n",
    "rate_beer_path_pickle = '../datas/RateBeer/pickles/df_rate_beer_'\n",
    "\n",
    "advocate_beers_path_pickle = beer_advocate_path_pickle + 'beers.pkl'\n",
    "advovate_breweries_path_pickle = beer_advocate_path_pickle + 'breweries.pkl'\n",
    "advocate_ratings_path_pickle = beer_advocate_path_pickle + 'ratings.pkl'\n",
    "advocate_reviews_path_pickle = beer_advocate_path_pickle + 'reviews.pkl'\n",
    "advocate_users_path_pickle = beer_advocate_path_pickle + 'users.pkl'\n",
    "\n",
    "matched_beer_beers_pickle = matched_beer_data_path_pickle + 'beers.pkl'\n",
    "matched_beer_breweries_pickle = matched_beer_data_path_pickle + 'breweries.pkl'\n",
    "matched_beer_ratings_ba_pickle = matched_beer_data_path_pickle + 'ratings_ba.pkl'\n",
    "matched_beer_ratings_rb_pickle = matched_beer_data_path_pickle + 'ratings_rb.pkl'\n",
    "matched_beer_ratings_pickle = matched_beer_data_path_pickle + 'ratings.pkl'\n",
    "matched_beer_users_approx_pickle = matched_beer_data_path_pickle + 'users_approx.pkl'\n",
    "matched_beer_users_pickle = matched_beer_data_path_pickle + 'users.csv'\n",
    "\n",
    "rate_beer_beers_pickle = rate_beer_path_pickle + 'beers.pkl'\n",
    "rate_beer_breweries_pickle = rate_beer_path_pickle + 'breweries.pkl'\n",
    "rate_beer_users_pickle = rate_beer_path_pickle + 'users.pkl'\n",
    "rate_beer_ratings_pickle = rate_beer_path_pickle + 'ratings.pkl'\n",
    "rate_beer_reviews_pickle = rate_beer_path_pickle + 'reviews.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define list of datas for each website\n",
    "datas_matched_beer_names = [\n",
    "    'df_matched_beer_beers',\n",
    "    'df_matched_beer_breweries',\n",
    "    'df_matched_beer_ratings_ba',\n",
    "    'df_matched_beer_ratings_rb',\n",
    "    'df_matched_beer_ratings',\n",
    "    'df_matched_beer_users_approx',\n",
    "    'df_matched_beer_users'\n",
    "    ]\n",
    "datas_advocate_names = [\n",
    "    'df_advocate_beers',\n",
    "    'df_advocate_breweries',\n",
    "    'df_advocate_ratings',\n",
    "    'df_advocate_reviews',\n",
    "    'df_advocate_users'\n",
    "    ]\n",
    "datas_rate_beer_names = [\n",
    "    'df_rate_beer_beers',\n",
    "    'df_rate_beer_breweries',\n",
    "    'df_rate_beer_users',\n",
    "    'df_rate_beer_ratings',\n",
    "    'df_rate_beer_reviews'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Format\n",
    "$\\color{Red}{\\text{Attention}}$ : Run the celluls in this section only if the datasets stored as pickle are not available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datas from Advovate Beer\n",
    "df_advocate_beers = pd.read_csv(advocate_beers_path, sep=',')\n",
    "df_advocate_breweries = pd.read_csv(advovate_breweries_path, sep=',')\n",
    "df_advocate_ratings = read_txt(advocate_ratings_path)\n",
    "df_advocate_reviews = read_txt(advocate_reviews_path)\n",
    "df_advocate_users = pd.read_csv(advocate_users_path, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datas from Matched Beer\n",
    "df_matched_beer_beers = pd.read_csv(matched_beer_beers, sep=',')\n",
    "df_matched_beer_breweries = pd.read_csv(matched_beer_breweries, sep=',')\n",
    "df_matched_beer_ratings_ba = read_txt(matched_beer_ratings_ba)\n",
    "df_matched_beer_ratings_rb = read_txt(matched_beer_ratings_rb)\n",
    "df_matched_beer_ratings = pd.read_csv(matched_beer_ratings, sep=',')\n",
    "df_matched_beer_users_approx = pd.read_csv(matched_beer_users_approx)\n",
    "df_matched_beer_users = pd.read_csv(matched_beer_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datas from Rate Beer\n",
    "df_rate_beer_beers = pd.read_csv(rate_beer_beers, sep=',')\n",
    "df_rate_beer_breweries = pd.read_csv(rate_beer_breweries, sep=',')\n",
    "df_rate_beer_users = pd.read_csv(rate_beer_users, sep=',')\n",
    "df_rate_beer_ratings = read_txt(rate_beer_ratings)\n",
    "df_rate_beer_reviews = read_txt(rate_beer_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading df_matched_beer_beers...\n",
      "Loading df_matched_beer_breweries...\n",
      "Loading df_matched_beer_ratings_ba...\n",
      "Loading df_matched_beer_ratings_rb...\n",
      "Loading df_matched_beer_ratings...\n",
      "Loading df_matched_beer_users_approx...\n",
      "Loading df_matched_beer_users...\n",
      "Loading df_advocate_beers...\n",
      "Loading df_advocate_breweries...\n",
      "Loading df_advocate_ratings...\n",
      "Loading df_advocate_reviews...\n",
      "Loading df_advocate_users...\n",
      "Loading df_rate_beer_beers...\n",
      "Loading df_rate_beer_breweries...\n",
      "Loading df_rate_beer_users...\n",
      "Loading df_rate_beer_ratings...\n",
      "Loading df_rate_beer_reviews...\n"
     ]
    }
   ],
   "source": [
    "#import raw data sets\n",
    "df_matched_beer_beers, df_matched_beer_breweries, df_matched_beer_ratings_ba, df_matched_beer_ratings_rb, df_matched_beer_ratings, df_matched_beer_users_approx, df_matched_beer_users = load_datas('matched_beer_data', datas_matched_beer_names)\n",
    "df_advocate_beers, df_advocate_breweries, df_advocate_ratings, df_advocate_reviews, df_advocate_users = load_datas('BeerAdvocate', datas_advocate_names)\n",
    "df_rate_beer_beers,df_rate_beer_breweries,df_rate_beer_users,df_rate_beer_ratings,df_rate_beer_reviews = load_datas('RateBeer', datas_rate_beer_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store dataFrame (Pickle format)\n",
    "Use this section to store the datasets in pickle (normally done once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define list of datas for each website\n",
    "datas_rate_beer = [df_rate_beer_beers,df_rate_beer_breweries,df_rate_beer_users,df_rate_beer_ratings,df_rate_beer_reviews]\n",
    "datas_matched_beer = [df_matched_beer_beers,df_matched_beer_breweries,df_matched_beer_ratings_ba,df_matched_beer_ratings_rb,df_matched_beer_ratings,df_matched_beer_users_approx,df_matched_beer_users]\n",
    "datas_advocate_beer = [df_advocate_beers,df_advocate_breweries,df_advocate_ratings,df_advocate_reviews,df_advocate_users]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving datas\n",
    "save_datas('RateBeer', datas_rate_beer,datas_rate_beer_names)\n",
    "save_datas('matched_beer_data', datas_matched_beer,datas_matched_beer_names)\n",
    "save_datas('BeerAdvocate', datas_advocate_beer,datas_advocate_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Initial data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Preprocessing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  A first merge is performed on user's datasets in order to have a single dataFrame. \n",
    "* Another merge is done on beer DataFrame to provide a single dataFrame containing all beers\n",
    "* A last merge is performed on ratings (for both Advocate and Rate Beer) to obtain a single dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_users = df_matched_beer_users\n",
    "users, mb_users_index = clean_mb_users(mb_users)\n",
    "advocate_users = deepcopy(df_advocate_users)\n",
    "advocate_users = clean_advocate_users(advocate_users)\n",
    "rb_users = df_rate_beer_users\n",
    "rb_users = clean_rb_users(rb_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_users = create_all_users(advocate_users,mb_users,rb_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_beers = df_advocate_beers\n",
    "rb_beers = df_rate_beer_beers\n",
    "mb_beers = df_matched_beer_beers\n",
    "adv_beers = clean_advocate_beers(adv_beers)\n",
    "rb_beers = clean_rb_beers(rb_beers)\n",
    "mb_beers = clean_mb_beers(mb_beers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_beers = create_all_beers(adv_beers,rb_beers,mb_beers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_ratings = df_advocate_ratings\n",
    "rb_ratings = df_rate_beer_ratings\n",
    "ba_ratings = clean_advocate_ratings(ba_ratings,df_all_beers)\n",
    "rb_ratings = clean_rb_ratings(rb_ratings,df_all_beers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating copies...\n",
      "processing dataframes...\n",
      "Merging dataframes...\n",
      "Concatenating dataframes...\n"
     ]
    }
   ],
   "source": [
    "df_ratings_stats = create_ratings_stat(ba_ratings,rb_ratings,df_all_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m df_adv_reviews \u001b[38;5;241m=\u001b[39m clean_advocate_reviews(df_advocate_reviews)\n\u001b[0;32m----> 2\u001b[0m df_rb_reviews \u001b[38;5;241m=\u001b[39m \u001b[43mclean_rb_reviews\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_rate_beer_reviews\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/document_vincent/epfl/master/ma1/applied_data_analysis/project/ada-2023-project-remontada/code/cleaning_functions/rate_beer.py:132\u001b[0m, in \u001b[0;36mclean_rb_reviews\u001b[0;34m(df_rate_beer_reviews)\u001b[0m\n\u001b[1;32m    129\u001b[0m df_rate_beer_reviews[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(pd\u001b[38;5;241m.\u001b[39mto_numeric(df_rate_beer_reviews[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]),unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Correct wrong character\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m df_rate_beer_reviews[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_rate_beer_reviews\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfix_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_rate_beer_reviews\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/ADA/lib/python3.12/site-packages/pandas/core/series.py:4760\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4632\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4633\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4634\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4635\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4636\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4751\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4752\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4754\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4758\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4760\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/ADA/lib/python3.12/site-packages/pandas/core/apply.py:1207\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/ADA/lib/python3.12/site-packages/pandas/core/apply.py:1287\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1281\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1286\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1287\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/ADA/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/ADA/lib/python3.12/site-packages/pandas/core/algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1818\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2920\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Documents/document_vincent/epfl/master/ma1/applied_data_analysis/project/ada-2023-project-remontada/code/cleaning_functions/rate_beer.py:132\u001b[0m, in \u001b[0;36mclean_rb_reviews.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    129\u001b[0m df_rate_beer_reviews[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(pd\u001b[38;5;241m.\u001b[39mto_numeric(df_rate_beer_reviews[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]),unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Correct wrong character\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m df_rate_beer_reviews[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_rate_beer_reviews[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mfix_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_rate_beer_reviews\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/ADA/lib/python3.12/site-packages/ftfy/__init__.py:358\u001b[0m, in \u001b[0;36mfix_text\u001b[0;34m(text, config, **kwargs)\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39munescape_html \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m segment:\n\u001b[1;32m    357\u001b[0m     config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39m_replace(unescape_html\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 358\u001b[0m fixed_segment, _ \u001b[38;5;241m=\u001b[39m \u001b[43mfix_and_explain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    359\u001b[0m out\u001b[38;5;241m.\u001b[39mappend(fixed_segment)\n\u001b[1;32m    360\u001b[0m pos \u001b[38;5;241m=\u001b[39m textbreak\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/ADA/lib/python3.12/site-packages/ftfy/__init__.py:396\u001b[0m, in \u001b[0;36mfix_and_explain\u001b[0;34m(text, config, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mfix_encoding:\n\u001b[1;32m    395\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 396\u001b[0m         text \u001b[38;5;241m=\u001b[39m \u001b[43mfix_encoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    398\u001b[0m         text, encoding_steps \u001b[38;5;241m=\u001b[39m fix_encoding_and_explain(text, config)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/ADA/lib/python3.12/site-packages/ftfy/__init__.py:594\u001b[0m, in \u001b[0;36mfix_encoding\u001b[0;34m(text, config, **kwargs)\u001b[0m\n\u001b[1;32m    592\u001b[0m     config \u001b[38;5;241m=\u001b[39m TextFixerConfig(explain\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    593\u001b[0m config \u001b[38;5;241m=\u001b[39m _config_from_kwargs(config, kwargs)\n\u001b[0;32m--> 594\u001b[0m fixed, _explan \u001b[38;5;241m=\u001b[39m \u001b[43mfix_encoding_and_explain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fixed\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/ADA/lib/python3.12/site-packages/ftfy/__init__.py:461\u001b[0m, in \u001b[0;36mfix_encoding_and_explain\u001b[0;34m(text, config, **kwargs)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     prevtext \u001b[38;5;241m=\u001b[39m text\n\u001b[0;32m--> 461\u001b[0m     text, plan \u001b[38;5;241m=\u001b[39m \u001b[43m_fix_encoding_one_step_and_explain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m plan \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    463\u001b[0m         plan_so_far\u001b[38;5;241m.\u001b[39mextend(plan)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/ADA/lib/python3.12/site-packages/ftfy/__init__.py:482\u001b[0m, in \u001b[0;36m_fix_encoding_one_step_and_explain\u001b[0;34m(text, config)\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ExplainedText(text, [])\n\u001b[1;32m    480\u001b[0m \u001b[38;5;66;03m# The first plan is to return ASCII text unchanged, as well as text\u001b[39;00m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;66;03m# that doesn't look like it contains mojibake\u001b[39;00m\n\u001b[0;32m--> 482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chardata\u001b[38;5;241m.\u001b[39mpossible_encoding(text, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mis_bad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ExplainedText(text, [])\n\u001b[1;32m    485\u001b[0m \u001b[38;5;66;03m# As we go through the next step, remember the possible encodings\u001b[39;00m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;66;03m# that we encounter but don't successfully fix yet. We may need them\u001b[39;00m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# later.\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/ADA/lib/python3.12/site-packages/ftfy/badness.py:392\u001b[0m, in \u001b[0;36mis_bad\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_bad\u001b[39m(text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    385\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Returns true iff the given text looks like it contains mojibake.\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;124;03m    longer, they have a higher chance of returning True for `is_bad(string)`.\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 392\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(\u001b[43mBADNESS_RE\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_adv_reviews = clean_advocate_reviews(df_advocate_reviews)\n",
    "df_rb_reviews = clean_rb_reviews(df_rate_beer_reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Diving in the datas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Distribution of the number of ratings per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_per_user = pd.DataFrame({'nbr_ratings':df_ratings_stats.groupby('user_id')['user_id'].count()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_per_user.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.ecdfplot(ratings_per_user, label=\"nbr_ratings\", complementary=True)\n",
    "plt.title('Cumulative histogram of the number of ratings per user (all websites)')\n",
    "plt.xlabel('Number of ratings')\n",
    "plt.ylabel('Proportion')\n",
    "plt.semilogx()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution has a heavy tail, indicating that there are numerous users who have posted only a few ratings, and conversely, a small number of users who are prolific raters. This observation motivates us to delve deeper into understanding the distinctions between these prolific raters and the rest of the user population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.a) Define who is a massive rater \n",
    "In order to separate people in two group, a definition of a massive rater, called from now an \"expert\" has to be found. The choice was made here to consider the number of ratings per year and aggregate scores from the past 3 years with the formula:\n",
    "$$\n",
    "S_{Y_j} = 2 * R_{Y_{j}} + 0.5 * R_{Y_{j-1}} + 0.25 * R_{Y_{j-2}} + 0.1 * R_{Y_{j-3}}\n",
    "$$\n",
    ", where $R_{Y_j}$ denotes the number of ratings for the year j and $S_{Y_j}$ is the score of the user for the year j.\n",
    "The experts are then people from the 0.995 quantile of the score calculate previously (among those who have a non-zero score i.e active users)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>year</th>\n",
       "      <th>nb_ratings</th>\n",
       "      <th>is_expert</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2000</td>\n",
       "      <td>44</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2001</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2000</td>\n",
       "      <td>94</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>2001</td>\n",
       "      <td>69</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  user_id  year  nb_ratings  is_expert\n",
       "0       2  2000          44      False\n",
       "1       2  2001           4      False\n",
       "2       2  2002           1      False\n",
       "3       3  2000          94      False\n",
       "4       3  2001          69      False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#define the expert users\n",
    "df_ratings_stat_expert, df_ratings_stat_pivot = compute_experts_table(df_ratings_stats)\n",
    "df_ratings_stat_expert.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a dictionary of experts per year\n",
    "experts_dict = {}\n",
    "for year in range(1996, 2018):\n",
    "    experts_dict[year] = df_ratings_stat_expert.loc[(df_ratings_stat_expert[\"year\"] == year) & (df_ratings_stat_expert[\"is_expert\"] == 1)].user_id.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_stats[\"is_expert\"]=df_ratings_stats[[\"user_id\",\"year\"]].apply(lambda x: 1 if x[\"user_id\"] in experts_dict[x[\"year\"]] else 0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expert_per_year = df_ratings_stat_expert.groupby('year').apply(lambda x: sum(x['is_expert']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expert_per_year.plot(kind='bar', figsize=(15,5))\n",
    "plt.ylabel('Number of experts')\n",
    "plt.xlabel('Year')\n",
    "plt.title('Number of experts per year')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Analysis of the behavior of the two categories\n",
    "#### 1.2.a) Mean of the ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this section is to analyze if the experts are more severe than the rest of the population on the global rating (column 'rating' in the DataFrame)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ratings_expert = []\n",
    "avg_ratings_normal = []\n",
    "ttest_expert_normal = []\n",
    "\n",
    "interest_years = sorted([year for year in df_ratings_stats.year.unique() if year > 2002])\n",
    "\n",
    "for year in interest_years:\n",
    "    df_expert_year = df_ratings_stat_expert.query('year == @year')\n",
    "    df_ratings_stat_year = df_ratings_stats.query('year == @year')\n",
    "    expert_of_the_year = df_expert_year[df_expert_year.is_expert].user_id\n",
    "    avg_expert = df_ratings_stat_year[df_ratings_stat_year['user_id'].isin(expert_of_the_year)]['rating'].mean()\n",
    "    avg_normal = df_ratings_stat_year[~df_ratings_stat_year['user_id'].isin(expert_of_the_year)]['rating'].mean()\n",
    "    ttest = stats.ttest_ind(df_ratings_stat_year[df_ratings_stat_year['user_id'].isin(expert_of_the_year)]['rating'], df_ratings_stat_year[~df_ratings_stat_year['user_id'].isin(expert_of_the_year)]['rating'])\n",
    "    ttest_expert_normal.append(ttest)\n",
    "    avg_ratings_expert.append(avg_expert)\n",
    "    avg_ratings_normal.append(avg_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar_width = 0.35\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "bar_positions1 = np.arange(len(avg_ratings_expert))\n",
    "bar_positions2 = bar_positions1 + bar_width\n",
    "\n",
    "ax.bar(bar_positions1, avg_ratings_normal, width=bar_width, label='Casuals', color='blue', alpha=0.7)\n",
    "ax.bar(bar_positions2, avg_ratings_expert, width=bar_width, label='Experts', color='red', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('Years')\n",
    "ax.set_ylabel('Average ratings')\n",
    "ax.set_title('Average of ratings between experts and casuals per year ')\n",
    "ax.set_xticks(bar_positions1 + bar_width / 2)\n",
    "ax.set_xticklabels(interest_years, rotation=45, ha='right')\n",
    "\n",
    "y_min = min(min(avg_ratings_normal), min(avg_ratings_expert)) - 1 \n",
    "y_max = max(max(avg_ratings_normal), max(avg_ratings_expert)) + 1 \n",
    "ax.set_ylim(y_min, y_max)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this graph it is clear that the expert are more severe, but let's verify with the mean of a T-Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(len(ttest_expert_normal)):\n",
    "    if ttest_expert_normal[year][1] < 0.05:\n",
    "        print(f'The p-value for the year {interest_years[year]} is {ttest_expert_normal[year][1]:.2e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The t-test tells that the hypothesis H0, under which the mean for the two groups are equals, can be rejected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.b) Top 10 rated beers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the assessment focuses on whether experts and the general population share similar preferences when it comes to rating beers. For this investigation, the beers are sorted based on the number of times they were rated. A comparison is then made between the top 10 beers for the two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_10_experts = pd.DataFrame()\n",
    "df_top_10_rest = pd.DataFrame()\n",
    "\n",
    "interest_years = sorted([year for year in df_ratings_stats.year.unique() if year > 2002])\n",
    "\n",
    "for year in interest_years:\n",
    "    top_10_rest = []\n",
    "    df_expert_year = df_ratings_stat_expert.query('year == @year')\n",
    "    df_ratings_stat_year = df_ratings_stats.query('year == @year')\n",
    "    expert_of_the_year = df_expert_year[df_expert_year.is_expert].user_id\n",
    "    top_10_rest = df_ratings_stat_year[~df_ratings_stat_year['user_id'].isin(expert_of_the_year)].copy()\n",
    "    top_10_rest = top_10_rest.groupby('beer_id').agg({'rating': 'count', 'beer_name': 'first'})\n",
    "    top_10_rest = top_10_rest.sort_values(by='rating', ascending=False).head(10)\n",
    "\n",
    "    df_top_10_rest[f'{year}'] = top_10_rest['beer_name'].values\n",
    "    top_10_experts = df_ratings_stat_year[df_ratings_stat_year['user_id'].isin(expert_of_the_year)].copy()\n",
    "    top_10_experts = top_10_experts.groupby('beer_id').agg({'rating': 'count', 'beer_name': 'first'})\n",
    "    top_10_experts = top_10_experts.sort_values(by='rating', ascending=False).head(10)\n",
    "    df_top_10_experts[f'{year}'] = top_10_experts['beer_name'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = {}\n",
    "for col in df_top_10_experts.columns:\n",
    "    value = df_top_10_experts[col].isin(df_top_10_rest[col]).sum()\n",
    "    similarity[col] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in similarity:\n",
    "    if similarity[key] > 0:\n",
    "        print(f'Year {key} has {similarity[key]} beer(s) in common')\n",
    "        common_beers = df_top_10_experts[df_top_10_experts[key].isin(df_top_10_rest[key])][key].values\n",
    "        print(common_beers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.c) We are going to see what kind (in terms of popularity) of beer casuals and expert rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each rating, we compute the number of ratings done the previous year on the rated beers. It gives an idea of the popularity of the rated beer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_beer_year=df_ratings_stats.groupby([\"beer_id\",\"year\"]).agg(\"size\").reset_index(name=\"count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_beer_year_shifted = df_grouped_beer_year.copy()\n",
    "df_grouped_beer_year_shifted['year'] += 1\n",
    "df_grouped_beer_year_shifted.rename(columns={\"count\": \"count_last_year\"}, inplace=True)\n",
    "df_ratings_stats = df_ratings_stats.merge(df_grouped_beer_year_shifted, how='left', on=['beer_id', 'year'])\n",
    "df_ratings_stats.fillna({\"count_last_year\":0}, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyse ratings of year 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_this_year,experts_this_year=filter_year_and_add_is_expert(df_ratings_stats,2016,df_ratings_stat_expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nbr_ratings_year_minus1_experts=df_ratings_this_year.loc[df_ratings_this_year[\"is_expert\"]==1][\"count_last_year\"]\n",
    "nbr_ratings_year_minus1_non_experts=df_ratings_this_year.loc[df_ratings_this_year[\"is_expert\"]==0][\"count_last_year\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "\n",
    "color = 'tab:orange'\n",
    "ax1.set_xlabel('Number of ratings per beer in 2015')\n",
    "ax1.set_ylabel('Ratings counts in 2016', color=color)\n",
    "ax1.hist(nbr_ratings_year_minus1_non_experts, bins=100, log=True, alpha=0.5, color=\"orange\", label=\"Non experts\",zorder=2)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid(False)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Ratings count in 2016', color=color)\n",
    "ax2.hist(nbr_ratings_year_minus1_experts, bins=100, log=True, alpha=0.5, color=\"blue\", label=\"Experts\",zorder=1)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.grid(False)\n",
    "red_patch = mpatches.Patch(color='orange', label='non experts')\n",
    "blue_patch = mpatches.Patch(color='blue', label='experts')\n",
    "ax1.legend(handles=[red_patch, blue_patch])\n",
    "plt.title(\"Distribution of number of ratings per beer in 2015 of ratings in 2016\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clearly see that experts rate less popular beers, let's perform a ttest to check this assumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(nbr_ratings_year_minus1_experts,nbr_ratings_year_minus1_non_experts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  ttest confirms the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we group the reults by user and use the mean this time :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_nbr_ratings_years_minus_one_per_user=df_ratings_this_year.groupby([\"user_id\",\"is_expert\"])[\"count_last_year\"].agg(\"mean\").reset_index().set_index(\"user_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_nbr_ratings_years_minus_one_per_user_experts=mean_nbr_ratings_years_minus_one_per_user.loc[mean_nbr_ratings_years_minus_one_per_user[\"is_expert\"]==1][\"count_last_year\"]\n",
    "mean_nbr_ratings_years_minus_one_per_user_non_experts=mean_nbr_ratings_years_minus_one_per_user.loc[mean_nbr_ratings_years_minus_one_per_user[\"is_expert\"]==0][\"count_last_year\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "\n",
    "color = 'orange'\n",
    "ax1.set_xlabel('Number of ratings per beer in 2015')\n",
    "ax1.set_ylabel('Users count in 2016', color=color)\n",
    "ax1.hist(mean_nbr_ratings_years_minus_one_per_user_non_experts, bins=100, log=True, alpha=0.5, color=\"orange\", label=\"Non experts\")\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "ax1.grid(False)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax2.set_ylabel('Users count in 2016', color=color)\n",
    "ax2.hist(mean_nbr_ratings_years_minus_one_per_user_experts, bins=100, log=True, alpha=1, color=color, label=\"Experts\")\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "ax2.grid(False)\n",
    "red_patch = mpatches.Patch(color='orange', label='non experts')\n",
    "blue_patch = mpatches.Patch(color='blue', label='experts')\n",
    "ax1.legend(handles=[red_patch, blue_patch])\n",
    "plt.title(\"Distribution of number of ratings per beer in 2015 of users who rated beers in 2016\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this graph, experts are located on the left side of the x-axis, meaning that they rate less popular beer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(mean_nbr_ratings_years_minus_one_per_user_experts,mean_nbr_ratings_years_minus_one_per_user_non_experts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The  ttest confirms the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.d) Analysis on the beers styles rated by experts and casuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saké have multiple styles, we just want to take one style for every saké\n",
    "df_ratings_stats['style'] =  df_ratings_stats['style'].str.replace(r'^Saké.*', 'Saké', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numbers of ratings per style\n",
    "ratings_per_style = df_ratings_stats.groupby('style').size().reset_index(name='rating_count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the numbers of rating for the first 16 Beer's Styles with more ratings\n",
    "\n",
    "sorted_ratings = ratings_per_style.sort_values(by='rating_count', ascending=False)\n",
    "\n",
    "top_16_styles = sorted_ratings.head(16)\n",
    "top_16 = top_16_styles['style'].unique()\n",
    "\n",
    "plt.bar(sorted_ratings['style'].head(16), sorted_ratings['rating_count'].head(16))\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.xlabel('Beer Styles')\n",
    "plt.ylabel('Rating Count')\n",
    "plt.title('Top 16 Beer Styles by Rating Count')\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let see the evolution over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats_per_year = df_ratings_stats.groupby(['style', 'year']).size().reset_index(name='nb_ratings')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_styles_peryear_pivot = df_stats_per_year.pivot(index='style', columns='year', values='nb_ratings')\n",
    "df_styles_peryear_pivot.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This table will show us the number of ratings per year per style for the top16 rated styles (n terms of number of ratings)\n",
    "\n",
    "df_top_16 = df_styles_peryear_pivot.loc[top_16]\n",
    "df_top_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the distribution of the top 16 rated Beer's Styles over time\n",
    "\n",
    "fig, axes = plt.subplots(4,4, figsize = (20,20), sharex = True)\n",
    "bins_ =10\n",
    "\n",
    "\n",
    "years_rating = df_ratings_stats['year'].unique()\n",
    "years_rating = sorted(years_rating)\n",
    "years_rating\n",
    "\n",
    "for i in range(0,4):\n",
    "    for j in range(0,4):\n",
    "        ax = axes[i,j]\n",
    "        current_style = top_16[i + 4 * j]\n",
    "        ax.set_title(current_style) \n",
    "        style_ratings = df_top_16.loc[current_style]\n",
    "        ax.bar(style_ratings.index, style_ratings.values, edgecolor='black')\n",
    "        ax.grid(False)\n",
    "        ax.set_xlabel('Year')\n",
    "        ax.set_ylabel('Number of Ratings')\n",
    "\n",
    "fig.suptitle('Number of Ratings per Year for Top 16 Styles', fontsize=20, y=1.02)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the evolution on time of the number of ratings per style (Plotting Expert and Non Expert evolution)\n",
    "\n",
    "years_ = [year for year in years_rating if year > 2001]\n",
    "n_rows = 4\n",
    "n_cols = 4\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 20), sharex=True)\n",
    "for i, year in enumerate(years_):\n",
    "    \n",
    "    row = i // n_cols\n",
    "    col = i % n_cols\n",
    "    df_expert_year = df_ratings_stat_expert.query('year == @year')\n",
    "    df_ratings_stat_year = df_ratings_stats.query('year == @year')\n",
    "    expert_of_the_year = df_expert_year[df_expert_year.is_expert].user_id\n",
    "    df_expert = df_ratings_stat_year[df_ratings_stat_year['user_id'].isin(expert_of_the_year)]\n",
    "    df_normal = df_ratings_stat_year[~df_ratings_stat_year['user_id'].isin(expert_of_the_year)]\n",
    "    df_stats_per_year_expert = df_expert.groupby(['style', 'year']).size().reset_index(name='nb_ratings')\n",
    "    df_stats_per_year_normal = df_normal.groupby(['style', 'year']).size().reset_index(name='nb_ratings')\n",
    "    df_styles_peryear_pivot_expert = df_stats_per_year_expert.pivot(index='style', columns='year', values='nb_ratings')\n",
    "    df_styles_peryear_pivot_expert.fillna(0, inplace=True)\n",
    "    df_styles_peryear_pivot_normal = df_stats_per_year_normal.pivot(index='style', columns='year', values='nb_ratings')\n",
    "    df_styles_peryear_pivot_normal.fillna(0, inplace=True)\n",
    "    for column in top_16:\n",
    "        if column not in df_styles_peryear_pivot_expert.index:\n",
    "            df_styles_peryear_pivot_expert.loc[column] = 0\n",
    "            df_styles_peryear_pivot_normal.loc[column] = 0\n",
    "    df_top_16_expert = df_styles_peryear_pivot_expert.loc[top_16]\n",
    "    df_top_16_normal = df_styles_peryear_pivot_normal.loc[top_16]\n",
    "    ax = axes[row, col]\n",
    "    ax.plot(df_top_16_normal.index, df_top_16_normal.values, label='Non expert', color='orange')\n",
    "    ax.set_xticks(df_top_16_normal.index,df_top_16_normal.index, rotation=45, ha='right')\n",
    "    ax.set_xlabel('Beer Styles')\n",
    "    ax.set_ylabel('Rating Count (Non experts)', color='black')\n",
    "    ax.tick_params(axis='y', labelcolor='black')\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.plot(df_top_16_expert.index, df_top_16_expert.values, label='Expert', color='blue',alpha=0.3)\n",
    "    ax2.set_ylabel('Rating Count (Expert)', color='blue')\n",
    "    ax2.tick_params(axis='y', labelcolor='blue')\n",
    "    ax.set_title(str(year))\n",
    "    ax.legend(loc='upper left')\n",
    "    ax2.legend(loc='upper right')\n",
    "    ax.grid(False)\n",
    "    ax2.grid(False)\n",
    "fig.suptitle('Experts and Non experts Ratings Counts for Top 16 Beer Styles by Year', fontsize=20, y=1.02)\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first years we observe that the distribution is similar between the experts and the others. However, the trend changes from year 2010. Since then, experts tend to rate different beers (in terms of style) than non experts. Plus, for certain beers, there are more ratings done by experts than non experts. Let's investigate this last point !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This show us the proportion over time of Expert (Blue) and Non Expert (Orange) rating \n",
    "\n",
    "fig,ax=plt.subplots(4,4,sharex=True)\n",
    "fig.set_size_inches(20,20)\n",
    "n_rows=4\n",
    "n_cols=4\n",
    "for i,style in enumerate(top_16):\n",
    "    df_style=df_ratings_stats.loc[df_ratings_stats[\"style\"]==style].groupby([\"year\",\"is_expert\"])[\"rating\"].agg(\"count\").reset_index()\n",
    "    df_style[\"rating\"]=df_style[\"rating\"]/df_style.groupby(\"year\")[\"rating\"].transform(\"sum\")\n",
    "    df_style.pivot(index=\"year\",columns=\"is_expert\",values=\"rating\").plot(kind=\"bar\",stacked=True,ax=ax[i//n_cols,i%n_cols],color=['orange', 'blue'])\n",
    "\n",
    "    ax[i//n_cols,i%n_cols].set_title(style)\n",
    "    ax[i//n_cols,i%n_cols].set_ylabel(\"Ratings proportion\")\n",
    "    red_patch = mpatches.Patch(color='orange', label='non experts')\n",
    "    blue_patch = mpatches.Patch(color='blue', label='experts')\n",
    "    ax[i//n_cols,i%n_cols].legend(handles=[red_patch, blue_patch])\n",
    "    ax[i//n_cols,i%n_cols].grid(False)\n",
    "    \n",
    "fig.suptitle(\"Rating proportion of experts and non experts for top 16 styles\",fontsize=20,y=1.02)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, even if experts account only for 0.5% of the active they represent a big part in the ratings of the beers. There are even some years and styles for which thew overtake non experts part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus their voice really matter since hey can make a huge difference for the final average rating displayed on websites."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It leads us to wonder if their ratings differentiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evolution on time of Experts and non Experts Grades Mean over Styles \n",
    "\n",
    "fig, axs = plt.subplots(4, 4, figsize=(20, 10), sharex = True, sharey = True)\n",
    "axs = axs.flatten()\n",
    "\n",
    "\n",
    "for i, year in enumerate(years_):\n",
    "    df_expert_year = df_ratings_stat_expert.query('year == @year')\n",
    "    df_ratings_stat_year = df_ratings_stats.query('year == @year')\n",
    "    expert_of_the_year = df_expert_year[df_expert_year.is_expert].user_id\n",
    "    df_expert = df_ratings_stat_year[df_ratings_stat_year['user_id'].isin(expert_of_the_year)]\n",
    "    df_normal = df_ratings_stat_year[~df_ratings_stat_year['user_id'].isin(expert_of_the_year)]\n",
    "    ratings_per_style_expert = df_expert.groupby('style')['rating'].mean().reset_index(name='rating_mean')\n",
    "    ratings_per_style_normal = df_normal.groupby('style')['rating'].mean().reset_index(name='rating_mean')\n",
    "    df_stats_per_year_expert = df_expert.groupby(['style', 'year'])['rating'].mean().reset_index(name='ratings_mean')\n",
    "    df_stats_per_year_normal = df_normal.groupby(['style', 'year'])['rating'].mean().reset_index(name='ratings_mean')\n",
    "    df_styles_peryear_pivot_expert = df_stats_per_year_expert.pivot(index='style', columns='year', values='ratings_mean')\n",
    "    df_styles_peryear_pivot_expert.fillna(0, inplace=True)\n",
    "    df_styles_peryear_pivot_normal = df_stats_per_year_normal.pivot(index='style', columns='year', values='ratings_mean')\n",
    "    df_styles_peryear_pivot_normal.fillna(0, inplace=True)\n",
    "    for column in top_16:\n",
    "        if column not in df_styles_peryear_pivot_expert.index:\n",
    "            df_styles_peryear_pivot_expert.loc[column] = 0\n",
    "            df_styles_peryear_pivot_normal.loc[column] = 0\n",
    "    df_top_16_expert = df_styles_peryear_pivot_expert.loc[top_16]\n",
    "    df_top_16_normal = df_styles_peryear_pivot_normal.loc[top_16]\n",
    "\n",
    "   \n",
    "    ax = axs[i]\n",
    "\n",
    "    ax.plot(df_top_16_expert.index, df_top_16_expert.values, label='Expert')\n",
    "    ax.plot(df_top_16_normal.index, df_top_16_normal.values, label='Normal')\n",
    "    ax.set_xticks(range(len(top_16)))\n",
    "    ax.set_xticklabels(top_16, rotation=45, ha='right')\n",
    "    ax.set_xlabel('Beer Styles')\n",
    "    ax.set_ylabel('Rating ')\n",
    "    ax.set_title('Top 16 Styles in Graded Beer Styles in ' + str(year))\n",
    "    ax.legend()\n",
    "    ax.grid(False)\n",
    "fig.suptitle('Experts and Non experts Ratings Means for Top 16 Rated Beer Styles by Year', fontsize=20, y=1.02)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that experts and non experts have similar behaviour on the most rated beer styles. Hence, we can say that highly-popular beers makers can work regardless of a side-effect of experts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.e) Now let's analyse how their ratings differentiate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the difference of ratings between experts and non experts for each beer (median)\n",
    "minimum_number_of_ratings=100\n",
    "YEAR=2017\n",
    "absolute_difference_ratings=[]\n",
    "\n",
    "df_ratings_this_year,experts_id=filter_year_and_add_is_expert(df_ratings_stats,YEAR,df_ratings_stat_expert)\n",
    "beers_with_enough_ratings=df_ratings_this_year.groupby(\"beer_id\").agg(\"size\").loc[df_ratings_this_year.groupby(\"beer_id\").agg(\"size\")>minimum_number_of_ratings].index.values\n",
    "df_advocate_ratings_this_year_with_enough_ratings=df_ratings_this_year.loc[df_ratings_this_year[\"beer_id\"].isin(beers_with_enough_ratings)]\n",
    "difference_ratings_medians=df_advocate_ratings_this_year_with_enough_ratings.groupby([\"beer_id\",\"is_expert\"])[\"rating\"].agg(\"median\")\n",
    "\n",
    "for beer_id in difference_ratings_medians.index.get_level_values(0).unique():\n",
    "    if 0 in difference_ratings_medians.loc[beer_id] and 1 in difference_ratings_medians.loc[beer_id]:\n",
    "        absolute_difference_ratings.append(np.abs(difference_ratings_medians.loc[beer_id,0]-difference_ratings_medians.loc[beer_id,1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of the difference of ratings between experts and non experts for each beer (median)\n",
    "plt.hist(absolute_difference_ratings,bins=50)\n",
    "plt.xlabel(\"Absolute difference in median ratings\")\n",
    "plt.ylabel(\"Number of beers\")\n",
    "plt.title(f\"Distribution of absolute difference in median ratings between experts and non experts \\n for beers with more than {minimum_number_of_ratings} ratings in {YEAR}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the difference of ratings between experts and non experts for each beer (mean and median)\n",
    "fig,ax=plt.subplots(int(np.ceil(len(np.arange(50,500,50))/3)),3,sharex=True)\n",
    "fig.set_size_inches(20,20)\n",
    "nb_bins=20\n",
    "\n",
    "for i,minimum_number_of_ratings in enumerate(np.arange(50,500,50)):\n",
    "    difference_ratings_medians_list=[]\n",
    "    difference_ratings_means_list=[]\n",
    "    beers_with_enough_ratings=df_ratings_this_year.groupby(\"beer_id\").agg(\"size\").loc[df_ratings_this_year.groupby(\"beer_id\").agg(\"size\")>minimum_number_of_ratings].index.values\n",
    "    df_advocate_ratings_this_year_with_enough_ratings=df_ratings_this_year.loc[df_ratings_this_year[\"beer_id\"].isin(beers_with_enough_ratings)]\n",
    "    difference_ratings_medians=df_advocate_ratings_this_year_with_enough_ratings.groupby([\"beer_id\",\"is_expert\"])[\"rating\"].agg(\"median\")\n",
    "    difference_ratings_means=df_advocate_ratings_this_year_with_enough_ratings.groupby([\"beer_id\",\"is_expert\"])[\"rating\"].agg(\"mean\")\n",
    "    \n",
    "    for beer_id in difference_ratings_medians.index.get_level_values(0).unique():\n",
    "        if 0 in difference_ratings_medians.loc[beer_id] and 1 in difference_ratings_medians.loc[beer_id]:\n",
    "            difference_ratings_medians_list.append(difference_ratings_medians.loc[beer_id,1]-difference_ratings_medians.loc[beer_id,0])\n",
    "            difference_ratings_means_list.append(difference_ratings_means.loc[beer_id,1]-difference_ratings_means.loc[beer_id,0])\n",
    "    if i==0:\n",
    "        difference_means_to_test=difference_ratings_means_list.copy()\n",
    "    ax[i//3,i%3].hist(difference_ratings_medians_list,alpha=0.5,bins=nb_bins,color=\"b\",label=\"median\")\n",
    "    ax[i//3,i%3].hist(difference_ratings_means_list,alpha=0.5,bins=nb_bins,color=\"orange\",label=\"mean\")\n",
    "    ax[i//3,i%3].axvline(0,c=\"r\",linestyle=\"--\")\n",
    "    ax[i//3,i%3].set_xlabel(\"difference in medians/means ratings (experts-non experts)\")\n",
    "    ax[i//3,i%3].set_ylabel(\"Number of beers\")\n",
    "    ax[i//3,i%3].set_title(\"Minimum number of ratings: \"+str(minimum_number_of_ratings))\n",
    "    ax[i//3,i%3].legend()\n",
    "fig.suptitle(\"Distribution of difference in median and mean ratings of experts - non experts for different minimum number of ratings of beers\",fontsize=15,y=1.02)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see that the experts tend to be more severe (negative difference), lets check if this trend holds for all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the distribution of the difference of ratings between experts and non experts over all beers (mean and median) for each year\n",
    "fig,ax=plt.subplots(4,3,sharex=True)\n",
    "fig.set_size_inches(20,20)\n",
    "nb_bins=20\n",
    "min_number_of_ratings=50\n",
    "\n",
    "for i,YEAR in enumerate(range(2006,2018)):\n",
    "  \n",
    "    difference_ratings_medians_list=[]\n",
    "    difference_ratings_means_list=[]\n",
    "    df_ratings_this_year,experts_id=filter_year_and_add_is_expert(df_ratings_stats,YEAR,df_ratings_stat_expert)\n",
    "    beers_with_enough_ratings=df_ratings_this_year.groupby(\"beer_id\").agg(\"size\").loc[df_ratings_this_year.groupby(\"beer_id\").agg(\"size\")>min_number_of_ratings].index.values\n",
    "    df_advocate_ratings_this_year_with_enough_ratings=df_ratings_this_year.loc[df_ratings_this_year[\"beer_id\"].isin(beers_with_enough_ratings)]\n",
    "    difference_ratings_medians=df_advocate_ratings_this_year_with_enough_ratings.groupby([\"beer_id\",\"is_expert\"])[\"rating\"].agg(\"median\")\n",
    "    difference_ratings_means=df_advocate_ratings_this_year_with_enough_ratings.groupby([\"beer_id\",\"is_expert\"])[\"rating\"].agg(\"mean\")\n",
    "    \n",
    "    for beer_id in difference_ratings_medians.index.get_level_values(0).unique():\n",
    "        if 0 in difference_ratings_medians.loc[beer_id] and 1 in difference_ratings_medians.loc[beer_id]:\n",
    "            difference_ratings_medians_list.append(difference_ratings_medians.loc[beer_id,1]-difference_ratings_medians.loc[beer_id,0])\n",
    "            difference_ratings_means_list.append(difference_ratings_means.loc[beer_id,1]-difference_ratings_means.loc[beer_id,0])\n",
    "            \n",
    "    ax[i//3,i%3].hist(difference_ratings_medians_list,alpha=0.5,bins=nb_bins,color=\"b\",label=\"median\")\n",
    "    ax[i//3,i%3].hist(difference_ratings_means_list,alpha=0.5,bins=nb_bins,color=\"orange\",label=\"mean\")\n",
    "    ax[i//3,i%3].axvline(0,c=\"r\",linestyle=\"--\")\n",
    "    ax[i//3,i%3].set_xlim(-1.25,1)\n",
    "    ax[i//3,i%3].set_xlabel(\"Difference in median ratings (experts-non experts)\")\n",
    "    ax[i//3,i%3].set_ylabel(\"Number of beers\")\n",
    "    ax[i//3,i%3].set_title(\"Year: \"+str(YEAR))\n",
    "    ax[i//3,i%3].legend()\n",
    "fig.suptitle(f\"Distribution of difference in median and mean ratings between (experts - non experts) for different years and minimum number of ratings of beers: {min_number_of_ratings}\",fontsize=15,y=1.02)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the trend is not that obvious now, grouping the results by beer show that we cannot say that in average experts are more severe (on beers that have at least 50 ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same but with beer that have at least 400 ratings (popular beers)\n",
    "fig,ax=plt.subplots(4,3,sharex=True)\n",
    "fig.set_size_inches(20,20)\n",
    "nb_bins=20\n",
    "min_number_of_ratings=400\n",
    "\n",
    "for i,YEAR in enumerate(range(2006,2018)):\n",
    "    difference_ratings_medians_list=[]\n",
    "    difference_ratings_means_list=[]\n",
    "    df_ratings_this_year,experts_id=filter_year_and_add_is_expert(df_ratings_stats,YEAR,df_ratings_stat_expert)\n",
    "    beers_with_enough_ratings=df_ratings_this_year.groupby(\"beer_id\").agg(\"size\").loc[df_ratings_this_year.groupby(\"beer_id\").agg(\"size\")>min_number_of_ratings].index.values\n",
    "    df_advocate_ratings_this_year_with_enough_ratings=df_ratings_this_year.loc[df_ratings_this_year[\"beer_id\"].isin(beers_with_enough_ratings)]\n",
    "    difference_ratings_medians=df_advocate_ratings_this_year_with_enough_ratings.groupby([\"beer_id\",\"is_expert\"])[\"rating\"].agg(\"median\")\n",
    "    difference_ratings_means=df_advocate_ratings_this_year_with_enough_ratings.groupby([\"beer_id\",\"is_expert\"])[\"rating\"].agg(\"mean\")\n",
    "    \n",
    "    for beer_id in difference_ratings_medians.index.get_level_values(0).unique():\n",
    "        if 0 in difference_ratings_medians.loc[beer_id] and 1 in difference_ratings_medians.loc[beer_id]:\n",
    "            difference_ratings_medians_list.append(difference_ratings_medians.loc[beer_id,1]-difference_ratings_medians.loc[beer_id,0])\n",
    "            difference_ratings_means_list.append(difference_ratings_means.loc[beer_id,1]-difference_ratings_means.loc[beer_id,0])\n",
    "            \n",
    "    ax[i//3,i%3].hist(difference_ratings_medians_list,alpha=0.5,bins=nb_bins,color=\"b\",label=\"median\")\n",
    "    ax[i//3,i%3].hist(difference_ratings_means_list,alpha=0.5,bins=nb_bins,color=\"orange\",label=\"mean\")\n",
    "    ax[i//3,i%3].axvline(0,c=\"r\",linestyle=\"--\")\n",
    "    ax[i//3,i%3].set_xlim(-1.25,1)\n",
    "    ax[i//3,i%3].set_xlabel(\"Difference in median ratings (experts-non experts)\")\n",
    "    ax[i//3,i%3].set_ylabel(\"Number of beers\")\n",
    "    ax[i//3,i%3].set_title(\"Year: \"+str(YEAR))\n",
    "    ax[i//3,i%3].legend()\n",
    "fig.suptitle(f\"Distribution of difference in median and mean ratings between (experts - non experts) for different years and minimum number of ratings of beers: {min_number_of_ratings}\",fontsize=15,y=1.02)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With beers that have at least 400 ratings (the year of the analysis), the results seem different since the distribution of the mean difference (orange) is denser in the negative values, it invites us to imagine that experts are more severe on popular beers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.f) Analysis of the ratings for specific beers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We analyse only ratings from Year 2016\n",
    "YEAR=2016\n",
    "df_ratings_this_year,experts_id=filter_year_and_add_is_expert(df_ratings_stats,YEAR,df_ratings_stat_expert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of some ratings for experts and non experts for different beers\n",
    "nrows=4\n",
    "fig,ax=plt.subplots(nrows,nrows)\n",
    "fig.set_size_inches(4*nrows,4*nrows)\n",
    "minimum_number_of_ratings=400\n",
    "bins=10\n",
    "for i in range(nrows*nrows):\n",
    "    np.random.seed(i)\n",
    "    beer_id_to_study=np.random.choice(df_ratings_this_year.groupby(\"beer_id\").agg(\"size\").loc[df_ratings_this_year.groupby(\"beer_id\").agg(\"size\")>minimum_number_of_ratings].index.values)\n",
    "    ratings_this_beer=df_ratings_this_year.loc[df_ratings_this_year[\"beer_id\"]==beer_id_to_study]\n",
    "    ratings_this_beer_experts=ratings_this_beer.loc[ratings_this_beer[\"is_expert\"]==1]\n",
    "    ratings_this_beer_non_experts=ratings_this_beer.loc[ratings_this_beer[\"is_expert\"]==0]\n",
    "    while len(ratings_this_beer_experts)==0 or len(ratings_this_beer_non_experts)==0:\n",
    "        beer_id_to_study=np.random.choice(df_ratings_this_year.groupby(\"beer_id\").agg(\"size\").loc[df_ratings_this_year.groupby(\"beer_id\").agg(\"size\")>minimum_number_of_ratings].index.values)\n",
    "        ratings_this_beer=df_ratings_this_year.loc[df_ratings_this_year[\"beer_id\"]==beer_id_to_study]\n",
    "        ratings_this_beer_experts=ratings_this_beer.loc[ratings_this_beer[\"is_expert\"]==1]\n",
    "        ratings_this_beer_non_experts=ratings_this_beer.loc[ratings_this_beer[\"is_expert\"]==0]\n",
    "\n",
    "    \n",
    "    difference_ttest=ttest_ind(ratings_this_beer_experts[\"rating\"],ratings_this_beer_non_experts[\"rating\"])\n",
    "    ax2 = ax[i//nrows,i%nrows].twinx()\n",
    "    ax2.hist(ratings_this_beer_experts[\"rating\"],bins=bins,alpha=0.3,label=\"Experts\",color=\"b\")\n",
    "    ax[i//nrows,i%nrows].hist(ratings_this_beer_non_experts[\"rating\"],bins=bins,alpha=0.5,label=\"Non experts\",color=\"orange\")\n",
    "    ax[i//nrows,i%nrows].axvline(ratings_this_beer_experts[\"rating\"].mean(),c=\"b\",linestyle=\"--\")\n",
    "    ax[i//nrows,i%nrows].axvline(ratings_this_beer_non_experts[\"rating\"].mean(),c=\"orange\",linestyle=\"--\")\n",
    "    \n",
    "    ax[i//nrows,i%nrows].set_xticks(np.arange(0,6,1),labels=np.arange(0,6,1))\n",
    "    ax[i//nrows,i%nrows].set_xlabel(\"Rating\")\n",
    "    ax[i//nrows,i%nrows].set_ylabel(\"Count (Non experts)\",color=\"orange\")\n",
    "    ax2.set_ylabel(\"Count (experts)\",color=\"b\")\n",
    "    ax[i//nrows, i%nrows].set_title(f\"Beer id: {beer_id_to_study} Nbr of ratings: {ratings_this_beer.shape[0]}\\n ttest diff, stat: {np.round(difference_ttest[0], 2)}, pvalue: {np.round(difference_ttest[1], 2)}\")\n",
    "    if i%nrows==0:\n",
    "        ax[i//nrows,i%nrows].legend()\n",
    "        ax2.legend(loc='center left')\n",
    "\n",
    "\n",
    "\n",
    "fig.suptitle(f\"Distribution of some ratings for experts and non experts for year {YEAR}\",y=1.01,fontsize=20)\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that for many beers, the difference of ratings is significant. Plus, experts seem not very likely to give excelent ratings (4.5 to 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should investigate the last point for later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.g) Ratings at the beginning of a beer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyse ratings of a specific beer over time\n",
    "def make_analysis_one_beer(beer_id_to_study):\n",
    "    ratings_this_beer=df_ratings_stats.loc[df_ratings_stats[\"beer_id\"]==beer_id_to_study]\n",
    "    ratings_this_beer.sort_values(by=\"date\",inplace=True)\n",
    "    ratings_this_beer[\"is_expert\"]=ratings_this_beer[[\"user_id\",\"year\"]].apply(lambda x: 1 if x[\"user_id\"] in experts_dict[x[\"year\"]] else 0,axis=1)\n",
    "    # group ratings by date and count the number of ratings for each date\n",
    "    ratings_by_date = ratings_this_beer.groupby(['date','is_expert']).size().reset_index(name='count')\n",
    "\n",
    "\n",
    "    # calculate the cumulative sum of the ratings\n",
    "    ratings_by_date['cumulative_count'] = ratings_by_date['count'].cumsum()\n",
    "\n",
    "    fig,ax=plt.subplots(1,2)\n",
    "    fig.set_size_inches(20,10)\n",
    "    # plot the evolution of the cumulative number of ratings over time\n",
    "    n=0\n",
    "    old_date=ratings_by_date[\"date\"].values[0]\n",
    "    for i,rating in ratings_by_date.iterrows():\n",
    "        if rating[\"is_expert\"]==1:\n",
    "            c=\"b\"\n",
    "            markersize=2\n",
    "        else:\n",
    "            c=\"orange\"\n",
    "            markersize=1\n",
    "        ax[0].plot([old_date,rating[\"date\"]],[n,rating[\"cumulative_count\"]],marker=\"o\",c=c,markersize=markersize)\n",
    "        n=rating[\"cumulative_count\"]\n",
    "        old_date=rating[\"date\"]\n",
    "        \n",
    "    fontsize_x_tiks=16\n",
    "    ax[0].set_xlabel('Date',fontsize=fontsize_x_tiks)\n",
    "    ax[0].set_ylabel('Cumulative number of ratings',fontsize=fontsize_x_tiks)\n",
    "    last_year=ratings_this_beer[\"year\"].values[-1]\n",
    "    first_year=ratings_this_beer[\"year\"].values[0]\n",
    "    xticks = np.array([pd.to_datetime(str(year), format='%Y') for year in range(first_year,last_year+1)])\n",
    "    if len(xticks)>5:\n",
    "        indexs_x_ticks=np.arange(0,len(xticks),len(xticks)//5)\n",
    "        indexs_x_ticks=np.floor(indexs_x_ticks).astype(int)\n",
    "        ax[0].set_xticks(xticks[indexs_x_ticks])\n",
    "    else:\n",
    "        ax[0].set_xticks(xticks)\n",
    "    \n",
    "    red_patch = mpatches.Patch(color='orange', label='non experts')\n",
    "    blue_patch = mpatches.Patch(color='blue', label='experts')\n",
    "    ax[0].legend(handles=[red_patch, blue_patch],fontsize=16)\n",
    "    \n",
    "    ratings_this_beer.groupby(\"year\")[\"rating\"].agg(\"mean\").plot(ax=ax[1],marker=\"o\",c=\"r\",markersize=5,linestyle=\"--\",label=\"mean rating experts\")\n",
    "    ax[1].set_xlabel('Year',fontsize=fontsize_x_tiks)\n",
    "    ax[1].set_ylabel('Mean rating of the year',fontsize=fontsize_x_tiks)\n",
    "    fig.suptitle(f'Evolution of cumulative number of ratings over time for beer {beer_id_to_study}',fontsize=20)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_analysis_one_beer(\"ba_4054\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we observe that in 2004 a non expert made a poor rating on this beer (about 1). However from 2008 to 2012, 3 experts rated this beer with a better grade (between 2.5 and 3). Then some experts and non experts rated this beer more often and with a better grade. We may imagine that experts played a key role in that case. By their early ratings they encouraged other raters to taste and rate this beer and for the last year (2017, which is the last year of our dataset), the grade was much higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_analysis_one_beer(\"rb_95399\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the situation is different, and the previous interpretation cannot be made. The situation is specfic to each beer. We should investigate those behaviours for P3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let see where the ratings come from, for different beers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analyse ratings of a different beers over time\n",
    "n_rows=4\n",
    "\n",
    "fig,ax=plt.subplots(n_rows,n_rows)\n",
    "fig.set_size_inches(4*n_rows,4*n_rows)\n",
    "for k in range(n_rows*n_rows):\n",
    "    if k==0:\n",
    "        beer_id_to_study=\"ba_27500\"\n",
    "    else:\n",
    "        beer_id_to_study=df_ratings_stats.sample(1)[\"beer_id\"].values[0]\n",
    "    ratings_this_beer=df_ratings_stats.loc[df_ratings_stats[\"beer_id\"]==beer_id_to_study]\n",
    "    ratings_this_beer.sort_values(by=\"date\",inplace=True)\n",
    "    ratings_this_beer[\"is_expert\"]=ratings_this_beer[[\"user_id\",\"year\"]].apply(lambda x: 1 if x[\"user_id\"] in experts_dict[x[\"year\"]] else 0,axis=1)\n",
    "    # group ratings by date and count the number of ratings for each date\n",
    "    ratings_by_date = ratings_this_beer.groupby(['date','is_expert']).size().reset_index(name='count')\n",
    "\n",
    "\n",
    "    # calculate the cumulative sum of the ratings\n",
    "    ratings_by_date['cumulative_count'] = ratings_by_date['count'].cumsum()\n",
    "\n",
    "    # plot the evolution of the cumulative number of ratings over time\n",
    "    n=0\n",
    "    old_date=ratings_by_date[\"date\"].values[0]\n",
    "   \n",
    "    for i,rating in ratings_by_date.iterrows():\n",
    "       \n",
    "        if rating[\"is_expert\"]==1:\n",
    "            c=\"b\"\n",
    "            markersize=2\n",
    "            \n",
    "        else:\n",
    "            c=\"orange\"\n",
    "            markersize=0.5\n",
    "            \n",
    "        ax[k//n_rows,k%n_rows].plot([old_date,rating[\"date\"]],[n,rating[\"cumulative_count\"]],marker=\"o\",c=c,markersize=markersize)\n",
    "       \n",
    "        n=rating[\"cumulative_count\"]\n",
    "        old_date=rating[\"date\"]\n",
    "    ax[k//n_rows,k%n_rows].set_xlabel('Date')\n",
    "    ax[k//n_rows,k%n_rows].set_ylabel('Cumulative number of ratings')\n",
    "    last_year=ratings_this_beer[\"year\"].values[-1]\n",
    "    first_year=ratings_this_beer[\"year\"].values[0]\n",
    "    xticks = np.array([pd.to_datetime(str(year), format='%Y') for year in range(first_year,last_year+1)])\n",
    "    if len(xticks)>3:\n",
    "        indexs_x_ticks=np.arange(0,len(xticks),len(xticks)//3)\n",
    "        indexs_x_ticks=np.floor(indexs_x_ticks).astype(int)\n",
    "        ax[k//n_rows,k%n_rows].set_xticks(xticks[indexs_x_ticks])\n",
    "    else:\n",
    "        ax[k//n_rows,k%n_rows].set_xticks(xticks)\n",
    "    ax[k//n_rows,k%n_rows].set_title(f'Beer id: {beer_id_to_study}')\n",
    "    red_patch = mpatches.Patch(color='orange', label='non experts')\n",
    "    blue_patch = mpatches.Patch(color='blue', label='experts')\n",
    "    ax[k//n_rows,k%n_rows].legend(handles=[red_patch, blue_patch])\n",
    "\n",
    "fig.suptitle(f'Evolution of cumulative number of ratings over time for 25 beers',y=1.01,fontsize=20)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While representing only 0.5% of active users, experts account for a lot in the beer ratings. Also It seems that for some beers, they represent a massive proportion of all ratings (especially for beer that do not have a lot of ratings).\n",
    "We should try to find a correspondance beetween the popularity of the beers (number over ratings) and the proportion  of ratings done by the experts at the beginning. We will tackle this issue for the next milestone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.h) Evolution of ratings over time, impact of the experts, bis \n",
    "#### Try to find beers which have been rated by expert and non experts at different years in order to identify if an expert tends to influence the ratings or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column 'group_size' to the DataFrame, representing the size of each group defined by 'beer_id', 'year', and 'is_expert'\n",
    "df_ratings_stats['group_size'] = df_ratings_stats.groupby(['beer_id', 'year', 'is_expert'])['rating'].transform('size')\n",
    "\n",
    "# In order to build confident intervals we need at least 10 ratings per beer\n",
    "df_ratings_stat_filtered = df_ratings_stats[df_ratings_stats['group_size'] >= 10].drop(columns='group_size')\n",
    "\n",
    "# Calculate the number of rows with is_expert = 1 for each beer_id\n",
    "expert_counts = df_ratings_stat_filtered[df_ratings_stat_filtered['is_expert'] == 1].groupby('beer_id')['is_expert'].sum()\n",
    "\n",
    "# Sort the results in descending order and select the top 16\n",
    "top_beer_ids = expert_counts.sort_values(ascending=False).head(16).index.tolist()\n",
    "\n",
    "result_df = df_ratings_stat_filtered[df_ratings_stat_filtered['beer_id'].isin(top_beer_ids)][['beer_id', 'beer_name']].drop_duplicates(subset=['beer_id'])\n",
    "\n",
    "beer_ids_to_study, beer_names_to_study = result_df['beer_id'].to_list(), result_df['beer_name'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# beer_ids_to_study, beer_names_to_study = zip(*df_ratings_stat_filtered[['beer_id', 'beer_name']].value_counts()[:16].index)\n",
    "\n",
    "# Create a 4x4 subplot grid\n",
    "fig, axes = plt.subplots(4, 4, figsize=(20, 20))\n",
    "\n",
    "# Flatten the 2D array of axes to iterate over it easily\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Iterate over beer_ids and corresponding subplots\n",
    "for i, (beer_id_to_study, beer_name_to_study) in enumerate(zip(beer_ids_to_study, beer_names_to_study)):\n",
    "    # Select ratings for the current beer_id\n",
    "    ratings_this_beer = df_ratings_stat_filtered.loc[df_ratings_stat_filtered[\"beer_id\"] == beer_id_to_study]\n",
    "    # Expert CI\n",
    "    ratings_this_beer_experts = ratings_this_beer[ratings_this_beer['is_expert'] == 1]\n",
    "    ratings_this_beer_experts = ratings_this_beer_experts.groupby([\"year\"])[\"rating\"].agg([\"std\",\"mean\",\"count\"]).reset_index()\n",
    "    ratings_this_beer_experts['CI95_up'] = ratings_this_beer_experts.apply(lambda x: x[\"mean\"] + 1.96 * x[\"std\"] / np.sqrt(x[\"count\"]), axis=1)\n",
    "    ratings_this_beer_experts['CI95_down'] = ratings_this_beer_experts.apply(lambda x: x[\"mean\"] - 1.96 * x[\"std\"] / np.sqrt(x[\"count\"]), axis=1) \n",
    "    # Casual CI\n",
    "    ratings_this_beer_casuals = ratings_this_beer[ratings_this_beer['is_expert'] == 0]\n",
    "    ratings_this_beer_casuals = ratings_this_beer_casuals.groupby([\"year\"])[\"rating\"].agg([\"std\",\"mean\",\"count\"]).reset_index()\n",
    "    ratings_this_beer_casuals['CI95_up'] = ratings_this_beer_casuals.apply(lambda x: x[\"mean\"] + 1.96 * x[\"std\"] / np.sqrt(x[\"count\"]), axis=1)\n",
    "    ratings_this_beer_casuals['CI95_down'] = ratings_this_beer_casuals.apply(lambda x: x[\"mean\"] - 1.96 * x[\"std\"] / np.sqrt(x[\"count\"]), axis=1) \n",
    "    # Plot on the current subplot\n",
    "    lineplot_expert = sns.lineplot(data=ratings_this_beer_experts, x='year', y='mean', label='Expert', ax=axes[i], color='blue')\n",
    "    lineplot_casual = sns.lineplot(data=ratings_this_beer_casuals, x='year', y='mean', label='Casual', ax=axes[i], color='red')\n",
    "    \n",
    "    # Fill between the confidence intervals\n",
    "    axes[i].fill_between(ratings_this_beer_experts['year'], ratings_this_beer_experts['CI95_down'], ratings_this_beer_experts['CI95_up'], \n",
    "                         color='blue', alpha=0.2)\n",
    "\n",
    "    axes[i].fill_between(ratings_this_beer_casuals['year'], ratings_this_beer_casuals['CI95_down'], ratings_this_beer_casuals['CI95_up'], \n",
    "                         color='red', alpha=0.2)\n",
    "\n",
    "    axes[i].set(xlabel=None, ylabel=None)\n",
    "    axes[i].set_title(f'Beer id: {beer_id_to_study}, name: {beer_name_to_study}')\n",
    "\n",
    "for ax in axes:\n",
    "    ax.set_xlim(2000, 2018)\n",
    "    ax.set_ylim(1, 5)  \n",
    " \n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig.text(0.5,0, \"Year\", fontsize=16)\n",
    "fig.text(0,0.5, \"Average rating\", rotation = 90, fontsize=16)\n",
    "fig.suptitle('Top 16 most rated beers by expert - Average ratings for expert and casuals, with 95% CI', fontsize=20,y=1.01)\n",
    "# Adjust layout to prevent overlapping\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the top 16 most rated beers (for experts), the plots illustrate that the expert ratings fluctuate more (confident interval are much bigger) than the ratings of the casuals , which tend to be more stable. We can also notice that the expert curve is almost everytime below the non-experts one, which means that the expert are more likely to be more strict about the grade of a beer. Another point is that the experts start giving rating after the casual ones and initially give a grade which is much smaller than casuals. However, the ratings of expert and casual tend to be much more closer to each other over the years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A next step should be to do the same kind of analysis on beers that do not have a lot of ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 2 Textual analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Process datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adv_reviews = load_pickle('../datas/df_adv_reviews.pkl')\n",
    "df_rb_reviews = load_pickle('../datas/df_rb_reviews.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(experts_dict, '../datas/experts_dict.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(df_all_users, '../datas/df_all_users.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating copies...\n",
      "processing dataframes...\n",
      "Merging dataframes...\n",
      "Concatenating dataframes...\n"
     ]
    }
   ],
   "source": [
    "from textual_analysis import create_text_dataset, compute_text_stats\n",
    "df_texts = create_text_dataset(df_adv_reviews,df_rb_reviews,df_all_users,experts_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(df_texts, '../datas/df_texts.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts_sampled = df_texts.sample(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting language and calculating number of words...\n",
      "Lemmatizing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/191 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E1041] Expected a string, Doc, or bytes as input, but got: <class 'list'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df_texts_experts, df_texts_others \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_text_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_texts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf_texts_sampled\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/document_vincent/epfl/master/ma1/applied_data_analysis/project/ada-2023-project-remontada/code/textual_analysis.py:111\u001b[0m, in \u001b[0;36mcompute_text_stats\u001b[0;34m(df_texts)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m    110\u001b[0m     batches \u001b[38;5;241m=\u001b[39m [df_texts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[i:i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m50\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(df_texts), \u001b[38;5;241m50\u001b[39m)]  \u001b[38;5;66;03m# Adjusted batch size to 50\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m     lemmatized_batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlemmatize_and_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mnlp\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# Flatten the list of lemmatized batches\u001b[39;00m\n\u001b[1;32m    114\u001b[0m df_texts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m [token \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m lemmatized_batches \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m batch]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/ADA/lib/python3.12/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1185\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py:317\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 317\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    319\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/lib/python3.12/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/Documents/document_vincent/epfl/master/ma1/applied_data_analysis/project/ada-2023-project-remontada/code/textual_analysis.py:161\u001b[0m, in \u001b[0;36mlemmatize_and_filter\u001b[0;34m(text, nlp)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlemmatize_and_filter\u001b[39m(text,nlp):\n\u001b[0;32m--> 161\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mnlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# Lemmatize each token and filter out stopwords and tokens in EXCLUDE_CHARS\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     filtered_tokens \u001b[38;5;241m=\u001b[39m [token\u001b[38;5;241m.\u001b[39mlemma_ \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m doc \u001b[38;5;28;01mif\u001b[39;00m token\u001b[38;5;241m.\u001b[39mlemma_ \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m EXCLUDE_CHARS \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m token\u001b[38;5;241m.\u001b[39mis_stop]\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/ADA/lib/python3.12/site-packages/spacy/language.py:1037\u001b[0m, in \u001b[0;36mLanguage.__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1018\u001b[0m     text: Union[\u001b[38;5;28mstr\u001b[39m, Doc],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     component_cfg: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Dict[\u001b[38;5;28mstr\u001b[39m, Any]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1022\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Doc:\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Apply the pipeline to some text. The text can span multiple sentences,\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;124;03m    and can contain arbitrary whitespace. Alignment into the original string\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;124;03m    is preserved.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;124;03m    DOCS: https://spacy.io/api/language#call\u001b[39;00m\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1037\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_doc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1038\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m component_cfg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1039\u001b[0m         component_cfg \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m~/.pyenv/versions/3.12.0/envs/ADA/lib/python3.12/site-packages/spacy/language.py:1131\u001b[0m, in \u001b[0;36mLanguage._ensure_doc\u001b[0;34m(self, doc_like)\u001b[0m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(doc_like, \u001b[38;5;28mbytes\u001b[39m):\n\u001b[1;32m   1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Doc(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab)\u001b[38;5;241m.\u001b[39mfrom_bytes(doc_like)\n\u001b[0;32m-> 1131\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE1041\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(doc_like)))\n",
      "\u001b[0;31mValueError\u001b[0m: [E1041] Expected a string, Doc, or bytes as input, but got: <class 'list'>"
     ]
    }
   ],
   "source": [
    "df_texts_experts, df_texts_others = compute_text_stats(df_texts=df_texts_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Compute most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visualization import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words_experts = compute_top_words(df_texts_experts)\n",
    "plot_top_words(top_words_experts, 'Experts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words_others = compute_top_words(df_texts_others)\n",
    "plot_top_words(top_words_others, 'Others')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts_experts[['nb_words','Neg_sentiment','Neu_sentiment','Pos_sentiment','Comp_sentiment']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts_others[['nb_words','Neg_sentiment','Neu_sentiment','Pos_sentiment','Comp_sentiment']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Statistical tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.1 Number of words per review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the number of words in the reviews between experts and non experts\n",
    "ttest_ind(df_texts_experts['nb_words'],df_texts_others['nb_words'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.2 Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the compund sentiment between experts and non experts\n",
    "ttest_ind(df_texts_experts['Comp_sentiment'], df_texts_others['Comp_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the negative sentiment between experts and non experts\n",
    "ttest_ind(df_texts_experts['Neg_sentiment'], df_texts_others['Neg_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the positive sentiment between experts and non experts\n",
    "ttest_ind(df_texts_experts['Pos_sentiment'], df_texts_others['Pos_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the neutral sentiment between experts and non experts\n",
    "ttest_ind(df_texts_experts['Neu_sentiment'], df_texts_others['Neu_sentiment'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
